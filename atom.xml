<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Cloud-oriented Life</title>
  
  <subtitle>Cloud Native Technology Improves Lives</subtitle>
  <link href="https://cloudolife.com/atom.xml" rel="self"/>
  
  <link href="https://cloudolife.com/"/>
  <updated>2025-06-10T09:49:34.923Z</updated>
  <id>https://cloudolife.com/</id>
  
  <author>
    <name>CloudoLife</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[Flutter FAQs] Fixing Failed to transform bcprov-jdk18on-1.78.1.jar</title>
    <link href="https://cloudolife.com/2025/06/07/Programming-Language/Dart/Flutter/FAQs/fixing-failed-to-transform-bcprov-jdk18on-1-78-1-jar/"/>
    <id>https://cloudolife.com/2025/06/07/Programming-Language/Dart/Flutter/FAQs/fixing-failed-to-transform-bcprov-jdk18on-1-78-1-jar/</id>
    <published>2025-06-07T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.923Z</updated>
    
    <content type="html"><![CDATA[<h1>Fixing Failed to transform bcprov-jdk18on-1.78.1.jar</h1><h2 id="Problem">Problem</h2><p>When building a Flutter APK with the command <code>flutter build apk --release src/main.dart</code>, the build process failed with the following error:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FAILURE: Build failed with an exception.</span><br><span class="line"></span><br><span class="line">* What went wrong:</span><br><span class="line">Execution failed for task &#x27;:camera_android:generateReleaseLintModel&#x27;.</span><br><span class="line">&gt; Could not resolve all files for configuration &#x27;:camera_android:releaseUnitTestRuntimeClasspath&#x27;.</span><br><span class="line">   &gt; Failed to transform bcprov-jdk18on-1.78.1.jar (org.bouncycastle:bcprov-jdk18on:1.78.1) to match attributes</span><br><span class="line">      &gt; Execution failed for JetifyTransform: bcprov-jdk18on-1.78.1.jar.</span><br><span class="line">         &gt; Failed to transform using Jetifier. Reason: IllegalArgumentException, message: Unsupported class file major version 65.</span><br></pre></td></tr></table></figure><p>The error indicated that the Java class file major version 65 (which corresponds to Java 21) was incompatible with the current build environment. This incompatibility occurred during the Jetifier transformation process when trying to process the BouncyCastle cryptography library.</p><span id="more"></span><h2 id="Root-Cause">Root Cause</h2><p>The issue stemmed from a Java version compatibility problem:</p><ul><li><strong>Java Class File Major Version 65</strong> corresponds to <strong>Java 21</strong></li><li>The build environment was using an older Java version that couldn’t process Java 21 compiled libraries</li><li>Jetifier, which converts Android Support libraries to AndroidX, couldn’t handle the newer bytecode format</li></ul><h2 id="Solution">Solution</h2><p>The fix involved a comprehensive approach addressing multiple compatibility layers:</p><h3 id="1-Update-Java-Version">1. Update Java Version</h3><p>Updated <code>.tool-versions</code> to use a compatible Java version:</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">- java adoptopenjdk-21.0.3+9.0.LTS</span></span><br><span class="line"><span class="addition">+ java adoptopenjdk-17.0.13+11</span></span><br></pre></td></tr></table></figure><p><strong>Rationale</strong>: Java 17 provides better compatibility with the current Flutter/Gradle ecosystem while supporting modern language features.</p><h3 id="2-Disable-Jetifier">2. Disable Jetifier</h3><p>Modified <code>android/gradle.properties</code>:</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">- android.enableJetifier=true</span></span><br><span class="line"><span class="addition">+ android.enableJetifier=false</span></span><br></pre></td></tr></table></figure><p><strong>Rationale</strong>: Since the project uses AndroidX libraries exclusively, Jetifier transformation is unnecessary and was causing the compatibility issue.</p><h3 id="3-Enhanced-Packaging-Configuration">3. Enhanced Packaging Configuration</h3><p>Added comprehensive packaging options in <code>android/app/build.gradle</code>:</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">packagingOptions &#123;</span><br><span class="line">    pickFirst <span class="string">&#x27;**/META-INF/androidx.localbroadcastmanager_localbroadcastmanager.version&#x27;</span></span><br><span class="line">    pickFirst <span class="string">&#x27;**/META-INF/androidx.core_core.version&#x27;</span></span><br><span class="line">    pickFirst <span class="string">&#x27;**/META-INF/androidx.appcompat_appcompat.version&#x27;</span></span><br><span class="line">    <span class="comment">// ... additional META-INF file handling</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">configurations</span>.all &#123;</span><br><span class="line">    <span class="keyword">exclude</span> <span class="keyword">group</span>: <span class="string">&#x27;com.android.support&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Rationale</strong>: Prevents conflicts when multiple dependencies include the same AndroidX metadata files and explicitly excludes deprecated Android Support libraries.</p><h3 id="4-AndroidX-Core-Component-Factory">4. AndroidX Core Component Factory</h3><p>Added to <code>android/app/src/main/AndroidManifest.xml</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">application</span></span></span><br><span class="line"><span class="tag">    <span class="attr">android:appComponentFactory</span>=<span class="string">&quot;androidx.core.app.CoreComponentFactory&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">tools:replace</span>=<span class="string">&quot;android:appComponentFactory&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>Rationale</strong>: Ensures proper AndroidX component initialization and resolves potential conflicts with legacy component factories.</p><h2 id="Key-Learnings">Key Learnings</h2><ol><li><p><strong>Java Version Alignment</strong>: Always ensure Java version compatibility across the entire build chain (Flutter, Gradle, Android SDK)</p></li><li><p><strong>Jetifier Assessment</strong>: Evaluate whether Jetifier is necessary for your project. Modern Flutter projects typically use AndroidX exclusively</p></li><li><p><strong>Proactive Dependency Management</strong>: Use explicit packaging rules to prevent META-INF conflicts in Android builds</p></li><li><p><strong>Version Monitoring</strong>: Regularly check for Java/Gradle compatibility matrices when updating dependencies</p></li></ol><h2 id="Verification">Verification</h2><p>After applying these changes, the build completed successfully:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flutter build apk --release src/main.dart</span><br><span class="line"><span class="comment"># ✅ Build successful</span></span><br></pre></td></tr></table></figure><p>This solution provides a robust foundation for future builds while maintaining compatibility with modern Android development practices.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Fixing Failed to transform bcprov-jdk18on-1.78.1.jar&lt;/h1&gt;
&lt;h2 id=&quot;Problem&quot;&gt;Problem&lt;/h2&gt;
&lt;p&gt;When building a Flutter APK with the command &lt;code&gt;flutter build apk --release src/main.dart&lt;/code&gt;, the build process failed with the following error:&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;FAILURE: Build failed with an exception.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;* What went wrong:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Execution failed for task &amp;#x27;:camera_android:generateReleaseLintModel&amp;#x27;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt; Could not resolve all files for configuration &amp;#x27;:camera_android:releaseUnitTestRuntimeClasspath&amp;#x27;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;gt; Failed to transform bcprov-jdk18on-1.78.1.jar (org.bouncycastle:bcprov-jdk18on:1.78.1) to match attributes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;gt; Execution failed for JetifyTransform: bcprov-jdk18on-1.78.1.jar.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &amp;gt; Failed to transform using Jetifier. Reason: IllegalArgumentException, message: Unsupported class file major version 65.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;The error indicated that the Java class file major version 65 (which corresponds to Java 21) was incompatible with the current build environment. This incompatibility occurred during the Jetifier transformation process when trying to process the BouncyCastle cryptography library.&lt;/p&gt;</summary>
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Dart" scheme="https://cloudolife.com/categories/Programming-Language/Dart/"/>
    
    <category term="Flutter" scheme="https://cloudolife.com/categories/Programming-Language/Dart/Flutter/"/>
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="Dart" scheme="https://cloudolife.com/tags/Dart/"/>
    
    <category term="Flutter" scheme="https://cloudolife.com/tags/Flutter/"/>
    
    <category term="bcprov-jdk18on-1.78.1" scheme="https://cloudolife.com/tags/bcprov-jdk18on-1-78-1/"/>
    
  </entry>
  
  <entry>
    <title>[[Node.js FAQs]] Fixing the mysterious `registry.nlark.com` 404 in your Node project</title>
    <link href="https://cloudolife.com/2025/05/31/Programming-Language/Node-js/FAQs/fixing-the-mysterious-registry-nlark-com-404-in-your-node-project/"/>
    <id>https://cloudolife.com/2025/05/31/Programming-Language/Node-js/FAQs/fixing-the-mysterious-registry-nlark-com-404-in-your-node-project/</id>
    <published>2025-05-31T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.932Z</updated>
    
    <content type="html"><![CDATA[<h1>Fixing the mysterious <code>registry.nlark.com</code> 404 in your Node project</h1><h2 id="The-Error">The Error</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm ERR! network request to https://registry.nlark.com/dom-to-image/download/dom-to-image-2.6.0.tgz failed</span><br><span class="line">npm ERR! code ENOTFOUND</span><br></pre></td></tr></table></figure><p>You’ll usually see this when running <code>npm install</code> (or <code>yarn install</code>) on a project last updated a few years ago.</p><span id="more"></span><h2 id="What’s-going-on">What’s going on?</h2><ul><li><strong><code>registry.nlark.com</code> no longer exists.</strong><br>The domain once pointed to Yuque’s private npm mirror (an Alibaba side-project). DNS now returns <strong>NXDOMAIN</strong>—meaning “this name is nowhere to be found”.</li><li><strong>Old lockfiles hard-code the mirror.</strong><br>Anything published between late 2019 – 2021 could have <code>registry.nlark.com</code> baked into <code>package-lock.json</code> or <code>yarn.lock</code>.</li></ul><h2 id="The-two-minute-fix">The two-minute fix</h2><ol><li><p><strong>Delete stale lockfiles</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -f package-lock.json yarn.lock</span><br></pre></td></tr></table></figure></li><li><p><strong>Re-install with the default registry</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install        <span class="comment"># or:  yarn install</span></span><br></pre></td></tr></table></figure><p>Fresh lockfiles will point at the official registry ( <code>https://registry.npmjs.org/</code> ) and you’re done.</p></li></ol><h2 id="Prefer-not-to-lose-lockfile-history">Prefer not to lose lockfile history?</h2><p>Search-and-replace the dead mirror with its modern twin, <strong><code>registry.npmmirror.com</code></strong> (a CDN-backed clone run by Tsinghua &amp; Alibaba).</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># macOS / Linux</span></span><br><span class="line">sed -i <span class="string">&#x27;&#x27;</span> <span class="string">&#x27;s#registry\.nlark\.com#registry.npmmirror.com#g&#x27;</span> package-lock.json yarn.lock</span><br><span class="line"><span class="comment"># Windows (PowerShell)</span></span><br><span class="line">(Get-Content package-lock.json) -replace <span class="string">&#x27;registry\.nlark\.com&#x27;</span>,<span class="string">&#x27;registry.npmmirror.com&#x27;</span> | Set-Content package-lock.json</span><br><span class="line">(Get-Content yarn.lock)        -replace <span class="string">&#x27;registry\.nlark\.com&#x27;</span>,<span class="string">&#x27;registry.npmmirror.com&#x27;</span> | Set-Content yarn.lock</span><br></pre></td></tr></table></figure><p>Then run <code>npm install</code> again.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Fixing the mysterious &lt;code&gt;registry.nlark.com&lt;/code&gt; 404 in your Node project&lt;/h1&gt;
&lt;h2 id=&quot;The-Error&quot;&gt;The Error&lt;/h2&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;npm ERR! network request to https://registry.nlark.com/dom-to-image/download/dom-to-image-2.6.0.tgz failed&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;npm ERR! code ENOTFOUND&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;You’ll usually see this when running &lt;code&gt;npm install&lt;/code&gt; (or &lt;code&gt;yarn install&lt;/code&gt;) on a project last updated a few years ago.&lt;/p&gt;</summary>
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Node.js" scheme="https://cloudolife.com/categories/Programming-Language/Node-js/"/>
    
    <category term="Node Package Manager (npm)" scheme="https://cloudolife.com/categories/Programming-Language/Node-js/Node-Package-Manager-npm/"/>
    
    <category term="Frequently Asked Questions (FAQs)" scheme="https://cloudolife.com/categories/Programming-Language/Node-js/Node-Package-Manager-npm/Frequently-Asked-Questions-FAQs/"/>
    
    
    <category term="Frequently Asked Questions (FAQs)" scheme="https://cloudolife.com/tags/Frequently-Asked-Questions-FAQs/"/>
    
    <category term="Node.js" scheme="https://cloudolife.com/tags/Node-js/"/>
    
    <category term="Node Package Manager (npm)" scheme="https://cloudolife.com/tags/Node-Package-Manager-npm/"/>
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="npm" scheme="https://cloudolife.com/tags/npm/"/>
    
  </entry>
  
  <entry>
    <title>[Flutter Drift] Ensuring Unique Primary Keys in Drift: Auto vs Manual ID</title>
    <link href="https://cloudolife.com/2025/05/09/Programming-Language/Dart/Flutter/Drift/ensuring-unique-primary-keys-in-drift-auto-vs-manual-id/"/>
    <id>https://cloudolife.com/2025/05/09/Programming-Language/Dart/Flutter/Drift/ensuring-unique-primary-keys-in-drift-auto-vs-manual-id/</id>
    <published>2025-05-09T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.922Z</updated>
    
    <content type="html"><![CDATA[<h1><strong>Ensuring Unique Primary Keys in Drift: Auto vs Manual ID</strong></h1><p>When working with the Drift ORM in Flutter, ensuring that your table’s primary key remains unique is essential for reliable data management. Depending on your data model, Drift offers two simple yet powerful approaches to enforce uniqueness:</p><span id="more"></span><h2 id="✅-1-Auto-Increment-Integer-ID-The-Simple-Way">✅ <strong>1. Auto-Increment Integer ID (The Simple Way)</strong></h2><p>For most use cases, letting the database handle ID generation is the easiest and safest choice:</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordMeanings</span> <span class="keyword">extends</span> <span class="title">Table</span> </span>&#123;</span><br><span class="line">  IntColumn <span class="keyword">get</span> id =&gt; integer().autoIncrement()(); <span class="comment">// Auto-increment primary key</span></span><br><span class="line">  IntColumn <span class="keyword">get</span> wordId =&gt; integer()();</span><br><span class="line">  TextColumn <span class="keyword">get</span> meaning =&gt; text()();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>With <code>autoIncrement()</code>, Drift guarantees that each new record gets a unique integer ID automatically. You don’t have to worry about duplicates — Drift will manage this for you.</p><h2 id="✅-2-Custom-ID-Types-Manual-Control">✅ <strong>2. Custom ID Types (Manual Control)</strong></h2><p>If you prefer more control, such as using a string ID (e.g., UUIDs, hashes, etc.), you can manually define the primary key:</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WordMeanings</span> <span class="keyword">extends</span> <span class="title">Table</span> </span>&#123;</span><br><span class="line">  TextColumn <span class="keyword">get</span> id =&gt; text()(); <span class="comment">// Custom string ID</span></span><br><span class="line">  IntColumn <span class="keyword">get</span> wordId =&gt; integer()();</span><br><span class="line">  TextColumn <span class="keyword">get</span> meaning =&gt; text()();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@override</span></span><br><span class="line">  <span class="built_in">Set</span>&lt;Column&gt; <span class="keyword">get</span> primaryKey =&gt; &#123;id&#125;; <span class="comment">// Explicitly define primary key</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>As long as you declare the <code>primaryKey</code> override, Drift will enforce uniqueness on the <code>id</code> field, regardless of its type.</p><h2 id="🔑-When-to-Use-Which">🔑 <strong>When to Use Which?</strong></h2><table><thead><tr><th>Scenario</th><th>Recommended Approach</th></tr></thead><tbody><tr><td>Simple numeric IDs</td><td>Auto-increment integers</td></tr><tr><td>Custom logic IDs (e.g., wordId+meaning hash)</td><td>Manual primary key declaration</td></tr></tbody></table><h2 id="✅-Conclusion">✅ <strong>Conclusion</strong></h2><p>Both auto-incremented integers and manually defined primary keys are fully supported in Drift. The choice depends on whether you want the database to handle ID uniqueness or if your business logic requires custom identifiers.</p><h2 id="References">References</h2><ul><li><a href="https://drift.simonbinder.eu/docs/">Drift Documentation</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1&gt;&lt;strong&gt;Ensuring Unique Primary Keys in Drift: Auto vs Manual ID&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;When working with the Drift ORM in Flutter, ensuring that your table’s primary key remains unique is essential for reliable data management. Depending on your data model, Drift offers two simple yet powerful approaches to enforce uniqueness:&lt;/p&gt;</summary>
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Dart" scheme="https://cloudolife.com/categories/Programming-Language/Dart/"/>
    
    <category term="Flutter" scheme="https://cloudolife.com/categories/Programming-Language/Dart/Flutter/"/>
    
    <category term="Drift" scheme="https://cloudolife.com/categories/Programming-Language/Dart/Flutter/Drift/"/>
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="Dart" scheme="https://cloudolife.com/tags/Dart/"/>
    
    <category term="Primary Key" scheme="https://cloudolife.com/tags/Primary-Key/"/>
    
    <category term="ID" scheme="https://cloudolife.com/tags/ID/"/>
    
    <category term="Structured Query Language (SQL)" scheme="https://cloudolife.com/tags/Structured-Query-Language-SQL/"/>
    
    <category term="SQL" scheme="https://cloudolife.com/tags/SQL/"/>
    
    <category term="Structured Query Language" scheme="https://cloudolife.com/tags/Structured-Query-Language/"/>
    
    <category term="Flutter" scheme="https://cloudolife.com/tags/Flutter/"/>
    
    <category term="Drift" scheme="https://cloudolife.com/tags/Drift/"/>
    
  </entry>
  
  <entry>
    <title>[Kubernetes (K8S) FAQs] Customizing /etc/hosts in Kubernetes Pods Using `hostAliases`</title>
    <link href="https://cloudolife.com/2025/05/03/Kubernetes-K8S/FAQs/custom-etc-hosts-kubernetes-hostaliases/"/>
    <id>https://cloudolife.com/2025/05/03/Kubernetes-K8S/FAQs/custom-etc-hosts-kubernetes-hostaliases/</id>
    <published>2025-05-03T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.918Z</updated>
    
    <content type="html"><![CDATA[<h1>Customizing /etc/hosts in Kubernetes Pods Using <code>hostAliases</code></h1><h2 id="Introduction"><strong>Introduction</strong></h2><p>In Kubernetes, managing hostname resolution for applications often requires overriding DNS settings or modifying container images. However, Kubernetes provides a simpler and cleaner solution: the <code>hostAliases</code> field. This feature allows you to inject custom entries into a Pod’s <code>/etc/hosts</code> file without altering the container itself.</p><p>In this blog, we’ll explore how to use <code>hostAliases</code> in Kubernetes Pods and Deployments, along with version requirements, practical examples, and troubleshooting tips.</p><span id="more"></span><h2 id="What-is-hostAliases"><strong>What is <code>hostAliases</code>?</strong></h2><p>The <code>hostAliases</code> field lets you define static IP-to-hostname mappings that are automatically added to the <code>/etc/hosts</code> file of all containers within a Pod. This is particularly useful for:</p><ul><li>Testing local services without DNS configuration.</li><li>Overriding DNS resolutions for specific hosts.</li><li>Resolving internal service names in development environments.</li></ul><hr><h2 id="Kubernetes-Version-Requirements"><strong>Kubernetes Version Requirements</strong></h2><p>The <code>hostAliases</code> feature has been available <strong>since Kubernetes v1.7</strong>. If your cluster is running a version older than v1.7 (which is unlikely, as these versions are long deprecated), you’ll need to upgrade to use this functionality.</p><hr><h2 id="Using-hostAliases-in-Pods"><strong>Using <code>hostAliases</code> in Pods</strong></h2><p>Here’s a basic example of a Pod definition with <code>hostAliases</code>:</p><pre><code class="language-yaml">apiVersion: v1kind: Podmetadata:  name: hostaliases-podspec:  hostAliases:    - ip: &quot;192.168.1.100&quot;      hostnames:        - &quot;foo.local&quot;        - &quot;bar.local&quot;    - ip: &quot;10.1.2.3&quot;      hostnames:        - &quot;test.abc&quot;  containers:    - name: nginx      image: nginx:latest</code></pre><p>After applying this configuration, the Pod’s <code>/etc/hosts</code> will include:</p><pre><code class="language-bash"># Kubernetes-managed hosts file127.0.0.1 localhost...192.168.1.100 foo.local bar.local10.1.2.3 test.abc</code></pre><p><strong>Key Notes:</strong></p><ol><li>Entries are appended and do not override default <code>localhost</code> mappings.</li><li>Changes require a Pod restart to take effect.</li></ol><hr><h2 id="Using-hostAliases-in-Deployments"><strong>Using <code>hostAliases</code> in Deployments</strong></h2><p>For Deployments, the <code>hostAliases</code> configuration is added under the Pod template section (<code>spec.template.spec</code>). Here’s an example:</p><pre><code class="language-yaml">apiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deployment  labels:    app: nginxspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      hostAliases:  # Correct placement        - ip: &quot;192.168.1.100&quot;          hostnames:            - &quot;foo.local&quot;            - &quot;bar.local&quot;      containers:        - name: nginx          image: nginx:latest          ports:            - containerPort: 80</code></pre><p><strong>Important Points:</strong></p><ul><li>The <code>hostAliases</code> field must be defined under <code>spec.template.spec</code>.</li><li>All replicas managed by the Deployment will inherit the same <code>/etc/hosts</code> entries.</li><li>To apply changes, run <code>kubectl apply -f deployment.yaml</code> and restart Pods if necessary.</li></ul><hr><h2 id="Verifying-hostAliases"><strong>Verifying <code>hostAliases</code></strong></h2><p>To confirm that the entries are added correctly:</p><ol><li>Access a Pod’s shell:<pre><code class="language-bash">kubectl exec -it &lt;pod-name&gt; -- sh</code></pre></li><li>Check the <code>/etc/hosts</code> file:<pre><code class="language-bash">cat /etc/hosts</code></pre>You should see your custom entries listed.</li></ol><hr><h2 id="Common-Issues-Fixes"><strong>Common Issues &amp; Fixes</strong></h2><h3 id="1-Misspelled-Field-Name">1. <strong>Misspelled Field Name</strong></h3><ul><li>❌ Incorrect: <code>hostAliases</code> (typo).</li><li>✅ Correct: <code>hostAliases</code>.</li></ul><h3 id="2-Changes-Not-Applied">2. <strong>Changes Not Applied</strong></h3><ul><li>Ensure you’ve run <code>kubectl apply</code>.</li><li>Delete old Pods to force the Deployment to recreate them:<pre><code class="language-bash">kubectl delete pod &lt;pod-name&gt;</code></pre></li></ul><h3 id="3-Cluster-Compatibility">3. <strong>Cluster Compatibility</strong></h3><ul><li>Verify your Kubernetes cluster version with <code>kubectl version</code>.</li><li>Upgrade if using a version older than v1.7.</li></ul><hr><h2 id="Conclusion"><strong>Conclusion</strong></h2><p>The <code>hostAliases</code> field is a simple yet powerful tool for managing hostname resolutions in Kubernetes. Whether you’re working with Pods or Deployments, it eliminates the need for DNS overrides or custom container images.</p><p><strong>Key Takeaways:</strong></p><ul><li>Works in Kubernetes v1.7+.</li><li>Define entries under <code>spec.template.spec</code> for Deployments.</li><li>Validate using <code>kubectl exec</code> and <code>cat /etc/hosts</code>.</li></ul><p>By leveraging <code>hostAliases</code>, you can streamline development workflows and ensure consistent hostname resolution across your applications.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Customizing /etc/hosts in Kubernetes Pods Using &lt;code&gt;hostAliases&lt;/code&gt;&lt;/h1&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In Kubernetes, managing hostname resolution for applications often requires overriding DNS settings or modifying container images. However, Kubernetes provides a simpler and cleaner solution: the &lt;code&gt;hostAliases&lt;/code&gt; field. This feature allows you to inject custom entries into a Pod’s &lt;code&gt;/etc/hosts&lt;/code&gt; file without altering the container itself.&lt;/p&gt;
&lt;p&gt;In this blog, we’ll explore how to use &lt;code&gt;hostAliases&lt;/code&gt; in Kubernetes Pods and Deployments, along with version requirements, practical examples, and troubleshooting tips.&lt;/p&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/categories/Cloud-Native/"/>
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/"/>
    
    <category term="FAQS" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/FAQS/"/>
    
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/tags/Kubernetes-K8S/"/>
    
    <category term="FAQS" scheme="https://cloudolife.com/tags/FAQS/"/>
    
    <category term="hostAliases" scheme="https://cloudolife.com/tags/hostAliases/"/>
    
    <category term="hostname" scheme="https://cloudolife.com/tags/hostname/"/>
    
  </entry>
  
  <entry>
    <title>[Flutter FAQs] Android Build Warning? Let&#39;s Decode That SDK Version Message</title>
    <link href="https://cloudolife.com/2025/04/26/Programming-Language/Dart/Flutter/FAQs/android-sdk-xml-version-warning-fix/"/>
    <id>https://cloudolife.com/2025/04/26/Programming-Language/Dart/Flutter/FAQs/android-sdk-xml-version-warning-fix/</id>
    <published>2025-04-26T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.923Z</updated>
    
    <content type="html"><![CDATA[<h1>Uh Oh! Android Build Warning? Let’s Decode That SDK Version Message</h1><p>Ever been happily building your Android app, only to be greeted by a cryptic warning message? You’re not alone! One common speed bump is the “SDK XML version” warning, often popping up when things aren’t quite aligned in your project setup. Let’s break down what this warning means and how you can usually fix it, without needing a computer science degree!</p><span id="more"></span><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Running Gradle task &#x27;assembleXXXRelease&#x27;...                     </span><br><span class="line">Warning: SDK processing. This version only understands SDK XML versions up to 3 but an SDK XML file of version 4 was encountered. This can happen if you use versions of Android Studio and the command-line tools that were released at different times.</span><br><span class="line">Running Gradle task &#x27;assembleXXXRelease&#x27;...  </span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Help investigate and resolve the SDK XML version warning?</p><h2 id="What’s-This-Warning-All-About">What’s This Warning All About?</h2><p>Imagine you and a friend are assembling the same piece of furniture, but you have version 4 of the instructions, and your friend has version 3. You might both finish, but you might encounter confusing steps or use slightly different parts because your manuals don’t match.</p><p>The “SDK XML version” warning is similar. It usually means different parts of your Android development toolkit (like Android Studio itself, the command-line tools you might use, or even settings within your project files) are expecting different versions of the Android Software Development Kit (SDK). The SDK is like the master set of tools and instructions for building Android apps. When one tool expects version 4 rules and another expects version 3, you get this warning.</p><h2 id="Why-Does-This-Happen">Why Does This Happen?</h2><p>This little mismatch can happen for a few reasons:</p><ol><li><p><strong>Tool Updates:</strong> Maybe you updated Android Studio but not the separate command-line tools, or vice-versa.</p></li><li><p><strong>Project Settings:</strong> Sometimes, the configuration files within your project (specifically a file called <code>build.gradle</code>) might have mismatched version numbers specified.</p></li></ol><p>The key culprits in your <code>build.gradle</code> file are usually:</p><ul><li><code>compileSdkVersion</code>: Tells Gradle which Android SDK version to compile your app with.</li><li><code>targetSdkVersion</code>: Tells Android which version your app was designed and tested for.</li></ul><p>If these numbers are inconsistent, or if one points to a version your tools don’t fully understand yet, the warning might appear.</p><h2 id="Taming-the-Warning-The-Usual-Fix">Taming the Warning: The Usual Fix</h2><p>Fixing this often involves making sure your project settings are consistent and up-to-date (but not <em>too</em> cutting-edge, unless you know what you’re doing!).</p><ol><li><p><strong>Peek into <code>build.gradle</code>:</strong> Open the <code>build.gradle</code> file located inside the <code>android/app</code> folder of your project.</p></li><li><p><strong>Check <code>compileSdkVersion</code>:</strong> Look for the line starting with <code>compileSdkVersion</code>. Make sure it’s set to a recent, stable Android SDK version number (like 34, which corresponds to Android 14). Avoid using versions that might be beta or preview unless intended.</p></li><li><p><strong>Check <code>targetSdkVersion</code>:</strong> Find the <code>targetSdkVersion</code> line. It’s generally best practice for this number to match your <code>compileSdkVersion</code>.</p></li></ol><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-       targetSdkVersion 33</span></span><br><span class="line"><span class="addition">+       targetSdkVersion 35</span></span><br></pre></td></tr></table></figure><ol start="4"><li><p><strong>Clean Up:</strong> After making changes, it’s a good idea to clean your project. If you’re using Flutter, run <code>flutter clean</code> in your terminal. Then, navigate into the <code>android</code> directory (<code>cd android</code>) and run <code>./gradlew clean</code>, then go back (<code>cd ..</code>).</p></li><li><p><strong>Try Building Again:</strong> Run your build command again.</p></li></ol><h2 id="Keep-Calm-and-Build-On">Keep Calm and Build On</h2><p>While build warnings can seem intimidating, the “SDK XML version” issue is usually just a sign that your tools or project settings need a quick tune-up. By ensuring your SDK versions are consistent in your <code>build.gradle</code> file, you can often resolve this warning and get back to building your amazing app. Happy coding!</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Uh Oh! Android Build Warning? Let’s Decode That SDK Version Message&lt;/h1&gt;
&lt;p&gt;Ever been happily building your Android app, only to be greeted by a cryptic warning message? You’re not alone! One common speed bump is the “SDK XML version” warning, often popping up when things aren’t quite aligned in your project setup. Let’s break down what this warning means and how you can usually fix it, without needing a computer science degree!&lt;/p&gt;</summary>
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Dart" scheme="https://cloudolife.com/categories/Programming-Language/Dart/"/>
    
    <category term="Flutter" scheme="https://cloudolife.com/categories/Programming-Language/Dart/Flutter/"/>
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="Xcode" scheme="https://cloudolife.com/tags/Xcode/"/>
    
    <category term="Dart" scheme="https://cloudolife.com/tags/Dart/"/>
    
    <category term="IntelliJ IDEA" scheme="https://cloudolife.com/tags/IntelliJ-IDEA/"/>
    
    <category term="Google" scheme="https://cloudolife.com/tags/Google/"/>
    
    <category term="Flutter" scheme="https://cloudolife.com/tags/Flutter/"/>
    
    <category term="flutter doctor" scheme="https://cloudolife.com/tags/flutter-doctor/"/>
    
    <category term="Android toolchain" scheme="https://cloudolife.com/tags/Android-toolchain/"/>
    
    <category term="Android Studio" scheme="https://cloudolife.com/tags/Android-Studio/"/>
    
    <category term="VS Code" scheme="https://cloudolife.com/tags/VS-Code/"/>
    
  </entry>
  
  <entry>
    <title>[Storage Disk] Expanding Disk Space on CentOS 7.x</title>
    <link href="https://cloudolife.com/2025/02/08/Cloud-Native/Cloud-Computing/Storage/Disk/expanding-disk-space-on-centos-7-x/"/>
    <id>https://cloudolife.com/2025/02/08/Cloud-Native/Cloud-Computing/Storage/Disk/expanding-disk-space-on-centos-7-x/</id>
    <published>2025-02-08T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.911Z</updated>
    
    <content type="html"><![CDATA[<h1>Expanding Disk Space on CentOS 7.x</h1><p>Running out of disk space on your Linux server? It’s a common problem, especially as your applications and data grow.  Today, we’ll walk through a practical guide to expand disk space on a CentOS 7.x cloud server. We’ll cover expanding both the root partition and an LVM logical volume. Let’s dive in!</p><span id="more"></span><h2 id="Understanding-the-Current-Disk-Setup">Understanding the Current Disk Setup</h2><p>First, let’s take a look at our current disk configuration using the lsblk command. This will show us the existing disks, partitions, and mount points.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lsblk</span><br><span class="line">NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">vda         253:0    0  100G  0 disk</span><br><span class="line">`-vda1      253:1    0   40G  0 part /</span><br><span class="line">vdb         253:16   0  500G  0 disk</span><br><span class="line">`-data-data 252:0    0  300G  0 lvm  /www</span><br></pre></td></tr></table></figure><p>As you can see from the output above:</p><p>We have two disks: vda (100GB) and vdb (500GB).<br>vda contains a partition vda1 of 40GB, which is mounted as the root filesystem (/).<br>vdb contains an LVM logical volume named data-data (part of volume group ‘data’), which is 300GB in size and mounted at /www.<br>Our goal is to fully utilize the available disk space and expand both the root partition and the /www volume.</p><h2 id="Expanding-the-Root-Partition">Expanding the Root Partition (/)</h2><p>Let’s start by expanding the root partition (/dev/vda1). Here are the steps:</p><p>Install growpart: This utility is used to expand partition sizes. If it’s not already installed, you can install it using yum:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install cloud-utils-growpart</span><br></pre></td></tr></table></figure><p>Expand the Partition: Use growpart to extend the partition.  We are expanding partition number 1 on /dev/vda.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo growpart /dev/vda 1</span><br></pre></td></tr></table></figure><p>Reload the Partition Table:  Inform the kernel about the partition table changes using partprobe.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo partprobe /dev/vda</span><br></pre></td></tr></table></figure><p>Resize the Filesystem: Finally, we need to resize the filesystem to utilize the newly added space.</p><p>For ext4 filesystem: If your root partition is formatted with ext4 (which is common), use resize2fs:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo resize2fs /dev/vda1</span><br></pre></td></tr></table></figure><p>For xfs filesystem: If your root partition uses xfs, use xfs_growfs. Note that for root filesystem, you can simply use / as the mount point.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo xfs_growfs /</span><br></pre></td></tr></table></figure><h2 id="Expanding-the-LVM-Logical-Volume-www">Expanding the LVM Logical Volume (/www)</h2><p>Now, let’s expand the LVM logical volume mounted at /www.  This volume is based on /dev/vdb. Here’s how to do it:</p><p>Resize the Physical Volume (PV):  First, resize the physical volume /dev/vdb to use the full disk space. We assume the entire /dev/vdb is used as a physical volume.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pvresize /dev/vdb</span><br></pre></td></tr></table></figure><p>Check Volume Group (VG) Free Space:  Use vgdisplay to check the available free space in the volume group (in this case, likely named ‘data’ based on the logical volume name data-data). Look for “Free PE / Size” in the output.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vgdisplay</span><br></pre></td></tr></table></figure><p>Extend the Logical Volume (LV):  Extend the logical volume data-data to use all the available free space in the volume group.  +100%FREE tells lvextend to use all the free space.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lvextend -l +100%FREE /dev/mapper/data-data</span><br></pre></td></tr></table></figure><p>Resize the Filesystem: Resize the filesystem on the logical volume to utilize the expanded space.</p><p>For ext4 filesystem: If /www is formatted with ext4:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo resize2fs /dev/mapper/data-data</span><br></pre></td></tr></table></figure><p>For xfs filesystem: If /www uses xfs, use xfs_growfs, specifying the mount point /www.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo xfs_growfs /www</span><br></pre></td></tr></table></figure><h2 id="Conclusion">Conclusion</h2><p>That’s it! You’ve successfully expanded both your root partition and your LVM logical volume on CentOS 7.x. By following these steps, you can efficiently manage your disk space and ensure your server has the storage it needs to run smoothly. Remember to always double-check your commands and consider backups before making changes to your disk partitions and filesystems.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Expanding Disk Space on CentOS 7.x&lt;/h1&gt;
&lt;p&gt;Running out of disk space on your Linux server? It’s a common problem, especially as your applications and data grow.  Today, we’ll walk through a practical guide to expand disk space on a CentOS 7.x cloud server. We’ll cover expanding both the root partition and an LVM logical volume. Let’s dive in!&lt;/p&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/categories/Cloud-Native/"/>
    
    <category term="Cloud Computing" scheme="https://cloudolife.com/categories/Cloud-Native/Cloud-Computing/"/>
    
    <category term="Storage" scheme="https://cloudolife.com/categories/Cloud-Native/Cloud-Computing/Storage/"/>
    
    <category term="Disk" scheme="https://cloudolife.com/categories/Cloud-Native/Cloud-Computing/Storage/Disk/"/>
    
    
    <category term="Linux" scheme="https://cloudolife.com/tags/Linux/"/>
    
    <category term="Cloud Native" scheme="https://cloudolife.com/tags/Cloud-Native/"/>
    
    <category term="Cloud Computing" scheme="https://cloudolife.com/tags/Cloud-Computing/"/>
    
    <category term="GNU&#39;s Not Unix! (GNU)" scheme="https://cloudolife.com/tags/GNU-s-Not-Unix-GNU/"/>
    
    <category term="Disk" scheme="https://cloudolife.com/tags/Disk/"/>
    
    <category term="Storage" scheme="https://cloudolife.com/tags/Storage/"/>
    
    <category term="parted" scheme="https://cloudolife.com/tags/parted/"/>
    
    <category term="xfs_growfs" scheme="https://cloudolife.com/tags/xfs-growfs/"/>
    
    <category term="resizepart" scheme="https://cloudolife.com/tags/resizepart/"/>
    
    <category term="XFS" scheme="https://cloudolife.com/tags/XFS/"/>
    
    <category term="Disk Partition" scheme="https://cloudolife.com/tags/Disk-Partition/"/>
    
    <category term="LVM" scheme="https://cloudolife.com/tags/LVM/"/>
    
  </entry>
  
  <entry>
    <title>[Kubernetes (K8S) FAQs] Troubleshooting Kubernetes Pod Startup Issues: Image Pull Failures </title>
    <link href="https://cloudolife.com/2025/02/01/Kubernetes-K8S/FAQs/troubleshooting-kubernetes-pod-startup-issues-image-pull-failures/"/>
    <id>https://cloudolife.com/2025/02/01/Kubernetes-K8S/FAQs/troubleshooting-kubernetes-pod-startup-issues-image-pull-failures/</id>
    <published>2025-02-01T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.918Z</updated>
    
    <content type="html"><![CDATA[<h1>Troubleshooting Kubernetes Pod Startup Issues: Image Pull Failures</h1><h2 id="Introduction">Introduction</h2><p>Recently, I encountered an issue where a Kubernetes (K8s) pod failed to start, getting stuck at:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pulling image &quot;docker.io/bitnami/minideb:stretch&quot;</span><br></pre></td></tr></table></figure><p>However, running <code>docker images</code> on the node showed that the image was already present.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker images | grep bitnami/minideb</span><br><span class="line">bitnami/minideb                                                     stretch                                    e398a222dbd6   2 years ago     53.8MB</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="Root-Cause-Analysis">Root Cause Analysis</h2><p>Upon deeper investigation, the issue was caused by:</p><ol><li><p><strong><code>imagePullPolicy: Always</code></strong></p><ul><li>Kubernetes was trying to pull the image every time, even though it was available locally.</li><li>This setting forces K8s to always fetch the latest image, which isn’t ideal for stable images that don’t change frequently.</li></ul></li><li><p><strong>Disk Usage Exceeding 70%</strong></p><ul><li>When disk usage goes beyond this threshold, Docker automatically starts cleaning up unused images.</li><li>The required image was deleted, causing the pod to fail during the pull operation.</li><li>Manually pulling the image using <code>docker pull</code> resolved this part of the issue.</li></ul></li><li><p><strong>Need to Inspect Logs Directly on the Node</strong></p><ul><li>GUI tools like <strong>Lens</strong> had outdated cache and continued displaying unrelated image pull errors from previous failed attempts.</li><li>Running <code>kubectl describe pod &lt;pod-name&gt;</code> directly on the K8s node provided the most accurate and real-time information.</li></ul></li></ol><h2 id="Solution">Solution</h2><p>To prevent such issues in the future, I applied the following fixes:</p><ol><li><p><strong>Modify Image Pull Policy</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br></pre></td></tr></table></figure><p>This ensures K8s only pulls the image if it is not already present locally.</p></li><li><p><strong>Monitor Disk Usage</strong></p><ul><li>Regularly check disk usage with <code>df -h</code> and clean up unused Docker resources using:<pre><code class="language-sh">docker system prune -a</code></pre></li></ul></li><li><p><strong>Use CLI Over GUI for Debugging</strong></p><ul><li>Always verify pod issues directly on the node using:<pre><code class="language-sh">kubectl describe pod &lt;pod-name&gt;</code></pre></li><li>This avoids misleading information caused by GUI caching issues.</li></ul></li></ol><h2 id="Conclusion">Conclusion</h2><p>This troubleshooting process reinforced the importance of understanding K8s image pull policies, monitoring disk space, and relying on CLI tools for accurate debugging. Hopefully, these insights help others facing similar Kubernetes startup issues! 🚀</p><h2 id="References">References</h2><p>[1] <a href="https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy">Kubernetes Image Pull Policy - https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy</a></p><p>[2] <a href="https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/">Troubleshooting Kubernetes Pods - https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/</a></p><p>[3] <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/">Kubernetes Node Disk Pressure and Eviction Policy - https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/</a></p><p>[4] <a href="https://docs.docker.com/config/pruning/">Docker Disk Cleanup Guide - https://docs.docker.com/config/pruning/</a></p><p>[5] <a href="https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/">crictl Command Reference (For Kubernetes CRI Debugging) - https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/</a></p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Troubleshooting Kubernetes Pod Startup Issues: Image Pull Failures&lt;/h1&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Recently, I encountered an issue where a Kubernetes (K8s) pod failed to start, getting stuck at:&lt;/p&gt;
&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Pulling image &amp;quot;docker.io/bitnami/minideb:stretch&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;However, running &lt;code&gt;docker images&lt;/code&gt; on the node showed that the image was already present.&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker images | grep bitnami/minideb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bitnami/minideb                                                     stretch                                    e398a222dbd6   2 years ago     53.8MB&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/categories/Cloud-Native/"/>
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/"/>
    
    <category term="FAQS" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/FAQS/"/>
    
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/tags/Kubernetes-K8S/"/>
    
    <category term="Cloud Native" scheme="https://cloudolife.com/tags/Cloud-Native/"/>
    
    <category term="Pod" scheme="https://cloudolife.com/tags/Pod/"/>
    
    <category term="Lens" scheme="https://cloudolife.com/tags/Lens/"/>
    
    <category term="imagePullPolicy" scheme="https://cloudolife.com/tags/imagePullPolicy/"/>
    
    <category term="FAQS" scheme="https://cloudolife.com/tags/FAQS/"/>
    
  </entry>
  
  <entry>
    <title>[Sentry FAQs] Locked Out? Reset Your Sentry Admin Password with createuser</title>
    <link href="https://cloudolife.com/2025/02/01/Awesome-Software/Development/Observability/Sentry/sentry-reset-admin-password-createuser/"/>
    <id>https://cloudolife.com/2025/02/01/Awesome-Software/Development/Observability/Sentry/sentry-reset-admin-password-createuser/</id>
    <published>2025-02-01T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.905Z</updated>
    
    <content type="html"><![CDATA[<h1>Locked Out? Reset Your Sentry Admin Password with <code>createuser</code></h1><p>Forgot your Sentry admin password and can’t log in? Don’t panic!  While password resets can sometimes be tricky, Sentry provides a straightforward command-line tool to create a new superuser account, effectively bypassing the login issue and granting you administrative access again. This guide will walk you through using the <code>sentry createuser --superuser</code> command to regain control of your Sentry instance.</p><span id="more"></span><h2 id="The-Problem-Forgotten-Admin-Password"><strong>The Problem: Forgotten Admin Password</strong></h2><p>It happens to the best of us. You might have forgotten your Sentry admin password, or perhaps the original administrator is no longer available.  When you try to log in, you’re met with the dreaded “incorrect password” message, leaving you locked out of your Sentry dashboard.</p><h2 id="The-Solution-sentry-createuser-superuser-to-the-Rescue"><strong>The Solution: <code>sentry createuser --superuser</code> to the Rescue</strong></h2><p>Sentry’s command-line interface (CLI) offers a powerful command: <code>createuser</code>.  When used with the <code>--superuser</code> flag, it allows you to create a brand new administrator account directly from your server’s command line.  Here’s how to use it:</p><p><strong>1. Access Your Sentry Server’s Command Line</strong></p><p>You’ll need to access the command-line terminal of your server where Sentry is installed. This might involve SSHing into a remote server or accessing the terminal of your local machine if you’re running Sentry locally.</p><p><strong>2. Execute the <code>createuser</code> Command</strong></p><p>Once you’re in the correct environment (ensure you can run <code>sentry</code> commands), execute the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentry createuser --superuser</span><br></pre></td></tr></table></figure><p><strong>3. Follow the Prompts</strong></p><p>The <code>sentry createuser --superuser</code> command will guide you through creating the new administrator account. You’ll be prompted to enter:</p><ul><li><strong>Username:</strong> Choose a username for your new admin account.</li><li><strong>Email:</strong>  Provide an email address associated with this admin account.</li><li><strong>Password:</strong>  Set a strong, new password for the administrator. You’ll be asked to confirm it.</li></ul><p><strong>4. Log in with Your New Credentials</strong></p><p>After successfully creating the new superuser account, you can now log in to your Sentry instance using the username and password you just created. You’ll have full administrator privileges.</p><h2 id="Important-Considerations"><strong>Important Considerations</strong></h2><ul><li><strong>New Account, Not Password Reset:</strong>  Keep in mind that <code>sentry createuser --superuser</code> creates a <em>new</em> administrator account. It does not reset the password of your <em>original</em> admin account. If you need to recover the old account, further investigation or password reset methods might be necessary (if possible).</li><li><strong>Security Best Practices:</strong>  Always use strong, unique passwords for administrator accounts. Store your credentials securely. Consider using a password manager.</li><li><strong>Command-Line Access Required:</strong> This method requires command-line access to your Sentry server. If you don’t have this access, you’ll need to explore alternative recovery methods (which might be more complex or require contacting your hosting provider).</li></ul><h2 id="Prevention-is-Key"><strong>Prevention is Key</strong></h2><p>To avoid getting locked out again, consider these preventative measures:</p><ul><li><strong>Password Management:</strong> Use a password manager to securely store and manage your Sentry admin password.</li><li><strong>Multiple Administrators:</strong>  Create multiple administrator accounts for redundancy. If one admin loses access, others can still manage the system.</li><li><strong>Document Credentials:</strong>  In a secure location, document the initial administrator credentials for emergency recovery purposes (for example, in an encrypted password vault).</li></ul><p>By using <code>sentry createuser --superuser</code>, you can quickly regain access to your Sentry instance when faced with a forgotten admin password.  Remember to practice good password management to prevent future lockouts!</p><h2 id="References">References</h2><p>[1] <a href="https://sentry.io/documentation/">Sentry Documentation -  https://sentry.io/documentation/</a></p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Locked Out? Reset Your Sentry Admin Password with &lt;code&gt;createuser&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Forgot your Sentry admin password and can’t log in? Don’t panic!  While password resets can sometimes be tricky, Sentry provides a straightforward command-line tool to create a new superuser account, effectively bypassing the login issue and granting you administrative access again. This guide will walk you through using the &lt;code&gt;sentry createuser --superuser&lt;/code&gt; command to regain control of your Sentry instance.&lt;/p&gt;</summary>
    
    
    
    <category term="Observability" scheme="https://cloudolife.com/categories/Observability/"/>
    
    <category term="Sentry" scheme="https://cloudolife.com/categories/Observability/Sentry/"/>
    
    
    <category term="Sentry" scheme="https://cloudolife.com/tags/Sentry/"/>
    
    <category term="Observability" scheme="https://cloudolife.com/tags/Observability/"/>
    
  </entry>
  
  <entry>
    <title>[Git FAQs] How to Enable Git LFS for a Repository and Track Large Files</title>
    <link href="https://cloudolife.com/2025/01/31/DevOps/Git/git-faqs-how-to-enable-git-lfs-for-a-repository-and-track-large-files/"/>
    <id>https://cloudolife.com/2025/01/31/DevOps/Git/git-faqs-how-to-enable-git-lfs-for-a-repository-and-track-large-files/</id>
    <published>2025-01-31T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.913Z</updated>
    
    <content type="html"><![CDATA[<h1>How to Enable Git LFS for a Repository and Track Large Files</h1><p>Git Large File Storage (LFS) is an extension for Git that allows efficient handling of large binary files by storing them outside the main Git repository while keeping lightweight pointers in place. This helps prevent repository bloat and improves performance when working with large files.</p><p>In this guide, we’ll cover:</p><ol><li><strong>How to enable Git LFS in a repository</strong></li><li><strong>How to track common large file types using Git LFS</strong></li></ol><span id="more"></span><h2 id="1-Enabling-Git-LFS-in-a-Repository"><strong>1. Enabling Git LFS in a Repository</strong></h2><p>Before you start tracking large files, you need to initialize Git LFS in your repository. Follow these steps:</p><h3 id="Step-1-Install-Git-LFS-if-not-already-installed"><strong>Step 1: Install Git LFS (if not already installed)</strong></h3><p>If Git LFS is not installed, install it using the following command:</p><h4 id="For-macOS-Homebrew"><strong>For macOS (Homebrew)</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install git-lfs</span><br></pre></td></tr></table></figure><h4 id="For-Ubuntu-Debian"><strong>For Ubuntu/Debian</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install git-lfs</span><br></pre></td></tr></table></figure><h4 id="For-Windows-via-Chocolatey"><strong>For Windows (via Chocolatey)</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">choco install git-lfs</span><br></pre></td></tr></table></figure><h3 id="Step-2-Initialize-Git-LFS-in-Your-Repository"><strong>Step 2: Initialize Git LFS in Your Repository</strong></h3><p>Navigate to your Git repository and run:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs install</span><br></pre></td></tr></table></figure><p>This initializes Git LFS for your system. If you want to make it default for all repositories, use:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs install --global</span><br></pre></td></tr></table></figure><h2 id="2-Tracking-Large-File-Types-in-Git-LFS"><strong>2. Tracking Large File Types in Git LFS</strong></h2><p>Once Git LFS is installed and initialized, you can start tracking large files. Below are some common file types that should be stored in Git LFS instead of the main Git repository.</p><h3 id="Step-3-Add-Common-Large-File-Types-to-Git-LFS"><strong>Step 3: Add Common Large File Types to Git LFS</strong></h3><p>Run the following commands to track different types of large files:</p><h4 id="1️⃣-Images"><strong>1️⃣ Images</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.png&quot;</span> <span class="string">&quot;*.jpg&quot;</span> <span class="string">&quot;*.jpeg&quot;</span> <span class="string">&quot;*.gif&quot;</span> <span class="string">&quot;*.svg&quot;</span></span><br></pre></td></tr></table></figure><h4 id="2️⃣-Videos"><strong>2️⃣ Videos</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.mp4&quot;</span> <span class="string">&quot;*.avi&quot;</span> <span class="string">&quot;*.mov&quot;</span> <span class="string">&quot;*.mkv&quot;</span></span><br></pre></td></tr></table></figure><h4 id="3️⃣-Audio-Files"><strong>3️⃣ Audio Files</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.mp3&quot;</span> <span class="string">&quot;*.wav&quot;</span> <span class="string">&quot;*.flac&quot;</span></span><br></pre></td></tr></table></figure><h4 id="4️⃣-Archives-Compressed-Files"><strong>4️⃣ Archives &amp; Compressed Files</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.zip&quot;</span> <span class="string">&quot;*.tar&quot;</span> <span class="string">&quot;*.gz&quot;</span> <span class="string">&quot;*.rar&quot;</span> <span class="string">&quot;*.7z&quot;</span> <span class="string">&quot;*.bz2&quot;</span> <span class="string">&quot;*.iso&quot;</span></span><br></pre></td></tr></table></figure><h4 id="5️⃣-Executables-Installers"><strong>5️⃣ Executables &amp; Installers</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.exe&quot;</span> <span class="string">&quot;*.dll&quot;</span> <span class="string">&quot;*.dmg&quot;</span> <span class="string">&quot;*.apk&quot;</span> <span class="string">&quot;*.ipa&quot;</span></span><br></pre></td></tr></table></figure><h4 id="6️⃣-Machine-Learning-Data-Files"><strong>6️⃣ Machine Learning &amp; Data Files</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.h5&quot;</span> <span class="string">&quot;*.hdf5&quot;</span> <span class="string">&quot;*.pth&quot;</span> <span class="string">&quot;*.pb&quot;</span> <span class="string">&quot;*.onnx&quot;</span> <span class="string">&quot;*.npy&quot;</span> <span class="string">&quot;*.npz&quot;</span></span><br></pre></td></tr></table></figure><h4 id="7️⃣-Office-Documents-Word-Excel-PowerPoint-PDF"><strong>7️⃣ Office Documents (Word, Excel, PowerPoint, PDF)</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.doc&quot;</span> <span class="string">&quot;*.docx&quot;</span> <span class="string">&quot;*.odt&quot;</span></span><br><span class="line">git lfs track <span class="string">&quot;*.xls&quot;</span> <span class="string">&quot;*.xlsx&quot;</span> <span class="string">&quot;*.ods&quot;</span> <span class="string">&quot;*.csv&quot;</span></span><br><span class="line">git lfs track <span class="string">&quot;*.ppt&quot;</span> <span class="string">&quot;*.pptx&quot;</span> <span class="string">&quot;*.odp&quot;</span></span><br><span class="line">git lfs track <span class="string">&quot;*.pdf&quot;</span></span><br></pre></td></tr></table></figure><h4 id="8️⃣-Design-3D-Files"><strong>8️⃣ Design &amp; 3D Files</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.psd&quot;</span> <span class="string">&quot;*.ai&quot;</span> <span class="string">&quot;*.sketch&quot;</span> <span class="string">&quot;*.blend&quot;</span></span><br><span class="line">git lfs track <span class="string">&quot;*.fbx&quot;</span> <span class="string">&quot;*.obj&quot;</span></span><br></pre></td></tr></table></figure><h4 id="9️⃣-Game-Development-Fonts"><strong>9️⃣ Game Development &amp; Fonts</strong></h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git lfs track <span class="string">&quot;*.unitypackage&quot;</span> <span class="string">&quot;*.pak&quot;</span> <span class="string">&quot;*.uasset&quot;</span> <span class="string">&quot;*.umap&quot;</span></span><br><span class="line">git lfs track <span class="string">&quot;*.ttf&quot;</span> <span class="string">&quot;*.otf&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Step-4-Commit-and-Push-Changes"><strong>Step 4: Commit and Push Changes</strong></h3><p>Once tracking rules are added, Git LFS updates a <code>.gitattributes</code> file in your repository. Commit and push the changes:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .gitattributes</span><br><span class="line">git commit -m <span class="string">&quot;Add Git LFS tracking for large files&quot;</span></span><br><span class="line">git push origin main</span><br></pre></td></tr></table></figure><h3 id="Step-5-Verify-Git-LFS-Tracking"><strong>Step 5: Verify Git LFS Tracking</strong></h3><p>To confirm that Git LFS is tracking the files, run:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs ls-files</span><br></pre></td></tr></table></figure><p>This command lists all files currently tracked by Git LFS.</p><h2 id="3-Handling-Existing-Large-Files-in-a-Git-Repository"><strong>3. Handling Existing Large Files in a Git Repository</strong></h2><p>If large files were already committed before enabling Git LFS, you should remove them from Git history and re-add them using LFS.</p><h3 id="Step-6-Remove-Previously-Committed-Large-Files"><strong>Step 6: Remove Previously Committed Large Files</strong></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">rm</span> --cached &lt;large-file&gt;</span><br><span class="line">git commit -m <span class="string">&quot;Remove large file from repository&quot;</span></span><br><span class="line">git lfs track <span class="string">&quot;&lt;large-file&gt;&quot;</span></span><br><span class="line">git add &lt;large-file&gt;</span><br><span class="line">git commit -m <span class="string">&quot;Re-add file to LFS&quot;</span></span><br><span class="line">git push origin main</span><br></pre></td></tr></table></figure><p>If multiple large files were previously committed, use the <strong>Git LFS migrate tool</strong>:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs migrate import --include=<span class="string">&quot;*.mp4,*.zip,*.exe&quot;</span></span><br></pre></td></tr></table></figure><h2 id="4-Prevent-Unwanted-Files-from-Being-Tracked"><strong>4. Prevent Unwanted Files from Being Tracked</strong></h2><p>To prevent unnecessary files (like macOS system files) from being tracked in Git, add them to <code>.gitignore</code>.</p><h3 id="Step-7-Ignore-Unwanted-Files"><strong>Step 7: Ignore Unwanted Files</strong></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;.DS_Store&quot;</span> &gt;&gt; .gitignore</span><br><span class="line">git add .gitignore</span><br><span class="line">git commit -m <span class="string">&quot;Ignore .DS_Store files&quot;</span></span><br><span class="line">git push origin main</span><br></pre></td></tr></table></figure><p>This ensures that <code>.DS_Store</code> and similar system files are never included in commits.</p><h2 id="5-Summary-Best-Practices"><strong>5. Summary &amp; Best Practices</strong></h2><table><thead><tr><th>File Type</th><th>Should Use LFS?</th><th>Example Extensions</th></tr></thead><tbody><tr><td><strong>Images</strong></td><td>✅ Yes</td><td><code>.png</code>, <code>.jpg</code>, <code>.gif</code></td></tr><tr><td><strong>Videos</strong></td><td>✅ Yes</td><td><code>.mp4</code>, <code>.avi</code>, <code>.mov</code></td></tr><tr><td><strong>Audio</strong></td><td>✅ Yes</td><td><code>.mp3</code>, <code>.wav</code>, <code>.flac</code></td></tr><tr><td><strong>Archives</strong></td><td>✅ Yes</td><td><code>.zip</code>, <code>.tar</code>, <code>.rar</code></td></tr><tr><td><strong>Executables</strong></td><td>✅ Yes</td><td><code>.exe</code>, <code>.dmg</code>, <code>.apk</code></td></tr><tr><td><strong>ML/Data Files</strong></td><td>✅ Yes</td><td><code>.h5</code>, <code>.onnx</code>, <code>.npy</code></td></tr><tr><td><strong>Office Docs</strong></td><td>✅ Yes</td><td><code>.docx</code>, <code>.xlsx</code>, <code>.pptx</code></td></tr><tr><td><strong>Design/3D Files</strong></td><td>✅ Yes</td><td><code>.psd</code>, <code>.ai</code>, <code>.blend</code></td></tr><tr><td><strong>Game Assets</strong></td><td>✅ Yes</td><td><code>.uasset</code>, <code>.unitypackage</code></td></tr><tr><td><strong>Source Code</strong></td><td>❌ No</td><td><code>.py</code>, <code>.js</code>, <code>.java</code></td></tr></tbody></table><h3 id="Key-Takeaways"><strong>Key Takeaways</strong></h3><p>✔️ Use <code>git lfs install</code> to enable LFS.<br>✔️ Use <code>git lfs track &quot;&lt;pattern&gt;&quot;</code> to specify which files to track.<br>✔️ Commit and push <code>.gitattributes</code> to apply LFS settings across the team.<br>✔️ Use <code>git lfs migrate import</code> to retroactively move large files to LFS.<br>✔️ Add <code>.gitignore</code> rules to exclude unnecessary files like <code>.DS_Store</code>.</p><p>By setting up Git LFS properly, you can <strong>keep your repository lightweight, improve performance, and avoid unnecessary bloating caused by large files</strong>. 🚀</p><p>Happy coding! 🎯</p><h2 id="References">References</h2><p>[1] <a href="https://git-lfs.github.com">Git LFS Official Documentation - https://git-lfs.github.com</a></p><p>[2] <a href="https://docs.github.com/en/github/managing-large-files">GitHub Docs: Managing Large Files - https://docs.github.com/en/github/managing-large-files</a></p><p>[3] <a href="https://www.atlassian.com/git/tutorials/git-lfs">Git LFS Tutorial by Atlassian - https://www.atlassian.com/git/tutorials/git-lfs</a></p><p>[4] <a href="https://www.git-tower.com/learn/git/cheat-sheet/git-lfs">Git LFS Cheat Sheet - https://www.git-tower.com/learn/git/cheat-sheet/git-lfs</a></p><p>[5] <a href="https://github.com/git-lfs/git-lfs/wiki/Tutorial">Git LFS FAQ - https://github.com/git-lfs/git-lfs/wiki/Tutorial</a></p><p>[6] <a href="https://www.gitkraken.com/learn/git/git-lfs">How to Migrate Existing Repositories to Git LFS - https://www.gitkraken.com/learn/git/git-lfs</a></p><p>[7] <a href="https://support.atlassian.com/bitbucket-cloud/docs/use-git-lfs-with-bitbucket/">Using Git LFS with Bitbucket - https://support.atlassian.com/bitbucket-cloud/docs/use-git-lfs-with-bitbucket/</a></p><p>[8] <a href="https://github.com/git-lfs/git-lfs/blob/main/docs/man/git-lfs.md">Git LFS Commands List - https://github.com/git-lfs/git-lfs/blob/main/docs/man/git-lfs.md</a></p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;How to Enable Git LFS for a Repository and Track Large Files&lt;/h1&gt;
&lt;p&gt;Git Large File Storage (LFS) is an extension for Git that allows efficient handling of large binary files by storing them outside the main Git repository while keeping lightweight pointers in place. This helps prevent repository bloat and improves performance when working with large files.&lt;/p&gt;
&lt;p&gt;In this guide, we’ll cover:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;How to enable Git LFS in a repository&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How to track common large file types using Git LFS&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="DevOps" scheme="https://cloudolife.com/categories/DevOps/"/>
    
    <category term="Git" scheme="https://cloudolife.com/categories/DevOps/Git/"/>
    
    
    <category term="Best Practices" scheme="https://cloudolife.com/tags/Best-Practices/"/>
    
    <category term="Git" scheme="https://cloudolife.com/tags/Git/"/>
    
    <category term="Git Large File Storage (LFS)" scheme="https://cloudolife.com/tags/Git-Large-File-Storage-LFS/"/>
    
    <category term="DevOps" scheme="https://cloudolife.com/tags/DevOps/"/>
    
    <category term="git lfs" scheme="https://cloudolife.com/tags/git-lfs/"/>
    
    <category term=".gitignore" scheme="https://cloudolife.com/tags/gitignore/"/>
    
    <category term=".gitattributes" scheme="https://cloudolife.com/tags/gitattributes/"/>
    
    <category term="Git Large File Storage" scheme="https://cloudolife.com/tags/Git-Large-File-Storage/"/>
    
    <category term="LFS" scheme="https://cloudolife.com/tags/LFS/"/>
    
  </entry>
  
  <entry>
    <title>[Alibaba Cloud] Troubleshooting Access Denied Errors in Alibaba Cloud OSS</title>
    <link href="https://cloudolife.com/2024/08/24/Cloud-Native/Cloud-Computing/Alibaba-Cloud/troubleshooting-access-denied-errors-in-alibaba-cloud-oss/"/>
    <id>https://cloudolife.com/2024/08/24/Cloud-Native/Cloud-Computing/Alibaba-Cloud/troubleshooting-access-denied-errors-in-alibaba-cloud-oss/</id>
    <published>2024-08-24T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.909Z</updated>
    
    <content type="html"><![CDATA[<h1>Troubleshooting Access Denied Errors in Alibaba Cloud OSS</h1><p>When working with Alibaba cloud storage, one of the most frustrating issues you can encounter is an “Access Denied” error, when you’re in the middle of transferring a file with <code>ossutil</code>. This blog post will walk you through a common issue related to Alibaba Cloud’s Object Storage Service (OSS) and how to quickly resolve it by properly configuring your <code>ossutil</code> tool.</p><span id="more"></span><h2 id="The-Problem-“You-have-no-right-to-access-this-object-”">The Problem: “You have no right to access this object.”</h2><p>Imagine you’re trying to copy a file named <code>a.log</code> to your OSS bucket using the <code>ossutil</code> command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ossutil cp a.log oss://backup/</span><br></pre></td></tr></table></figure><p>Instead of a smooth transfer, you receive an error message that looks something like this:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">retry count: 9, multipart upload file: a.log.</span><br><span class="line">Total num: 1, size: 648,565,608. Dealed num: 0, Transfer size: 0. When error happens.</span><br><span class="line">Error: oss: service returned error: StatusCode=403, ErrorCode=AccessDenied, ErrorMessage=&quot;You have no right to access this object.&quot;, RequestId=xxxxxxxxxxxx, File=a.log</span><br></pre></td></tr></table></figure><p>This error, with the <code>403</code> status code and <code>AccessDenied</code> message, indicates that the OSS service has refused your request due to insufficient permissions.</p><h3 id="Common-Causes">Common Causes</h3><p>This error can be caused by a variety of issues:</p><ol><li><strong>Invalid OSS Credentials</strong>: The access key or secret key you are using might be incorrect or have insufficient permissions.</li><li><strong>Incorrect Bucket Policies</strong>: The bucket might have policies that restrict access from your account or specific actions.</li><li><strong>Region Endpoint Mismatch</strong>: The endpoint you’re using might not correspond to the region where your OSS bucket is located.</li><li><strong>Improperly Configured ossutil</strong>: This is the most likely culprit in many cases, particularly if the endpoint is misconfigured.</li></ol><h3 id="The-Solution-Checking-and-Correcting-the-Endpoint">The Solution: Checking and Correcting the Endpoint</h3><p>The key to resolving this issue often lies in the configuration file used by <code>ossutil</code>, located at <code>~/.ossutilconfig</code>. This file stores important information such as your credentials and the endpoint you are using to interact with OSS.</p><h4 id="Step-1-Locate-Your-Configuration-File">Step 1: Locate Your Configuration File</h4><p>First, open your configuration file with a text editor:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ossutilconfig</span><br></pre></td></tr></table></figure><p>You should see something like this:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Credentials]</span><br><span class="line">endpoint=oss-cn-hongkong-internal.aliyuncs.com</span><br><span class="line">accessKeyID=yourAccessKeyID</span><br><span class="line">accessKeySecret=yourAccessKeySecret</span><br></pre></td></tr></table></figure><h4 id="Step-2-Update-the-Endpoint-Protocol">Step 2: Update the Endpoint Protocol</h4><p>The issue often arises from using an endpoint without specifying the correct protocol (HTTP/HTTPS). For example, the endpoint might be set to <code>oss-cn-hongkong-internal.aliyuncs.com</code>, which is an internal address that typically does not use HTTPS.</p><p>To resolve the access issue, update the endpoint to explicitly use HTTPS:</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># ~/.ossutilconfig</span><br><span class="line"></span><br><span class="line"><span class="deletion">- endpoint=oss-cn-hongkong-internal.aliyuncs.com</span></span><br><span class="line"><span class="addition">+ endpoint=https://oss-cn-hongkong-internal.aliyuncs.com</span></span><br></pre></td></tr></table></figure><p>This change forces <code>ossutil</code> to communicate with OSS over a secure HTTPS connection, which is often required for access.</p><h4 id="Step-3-Save-and-Retry">Step 3: Save and Retry</h4><p>After saving the changes to your <code>~/.ossutilconfig</code> file, retry your <code>ossutil cp</code> command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ossutil cp a.log oss://backup/</span><br></pre></td></tr></table></figure><p>If the issue was related to the endpoint configuration, the transfer should now proceed without any access errors.</p><h3 id="Why-the-Endpoint-Matters">Why the Endpoint Matters</h3><p>The endpoint in OSS configuration specifies the URL used to access your bucket and the region in which the bucket resides. Each region has its specific endpoint, and using the correct one ensures that your requests are routed properly.</p><ul><li><strong>Internal vs. External Endpoints</strong>: Internal endpoints (e.g., <code>oss-cn-hongkong-internal.aliyuncs.com</code>) are often used within Alibaba Cloud’s network, typically for performance reasons. However, these might not be accessible from outside the network or may require specific protocols like HTTPS for secure access.</li><li><strong>Protocol Matters</strong>: Using HTTP might be blocked by security policies, especially for buckets configured to only accept HTTPS connections.</li></ul><h3 id="Additional-Tips">Additional Tips</h3><ul><li><strong>Check Your Permissions</strong>: Ensure that your Alibaba Cloud account or RAM (Resource Access Management) user has the necessary permissions to perform actions on the bucket.</li><li><strong>Validate Bucket Policies</strong>: Review the bucket’s access control policies to confirm they allow the actions you’re attempting.</li><li><strong>Region and Endpoint Alignment</strong>: Always ensure that the endpoint you specify corresponds to the region where your bucket is located. For more information, see the Alibaba Cloud documentation on <a href="https://www.alibabacloud.com/help/en/oss/user-guide/regions-and-endpoints#concept-zt4-cvy-5db">Regions and Endpoints</a>.</li></ul><h2 id="Conclusion">Conclusion</h2><p>Encountering a “You have no right to access this object” error while using Alibaba Cloud’s OSS can be a hassle, but in many cases, it’s simply a matter of correcting your <code>ossutil</code> configuration. By ensuring that your endpoint is correctly set with the <code>https://</code> prefix, you can often resolve these access issues quickly and get back to working with your cloud storage without further delays.</p><p>For more detailed information on configuring <code>ossutil</code>, refer to the <a href="https://www.alibabacloud.com/help/en/oss/developer-reference/configure-ossutil">Alibaba Cloud Documentation - https://www.alibabacloud.com/help/en/oss/developer-reference/configure-ossutil</a>.</p><p>This blog post aimed to provide a concise yet comprehensive guide to troubleshooting a common OSS access issue. By following these steps, you can minimize downtime and maintain smooth operations in your cloud-based workflows.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Troubleshooting Access Denied Errors in Alibaba Cloud OSS&lt;/h1&gt;
&lt;p&gt;When working with Alibaba cloud storage, one of the most frustrating issues you can encounter is an “Access Denied” error, when you’re in the middle of transferring a file with &lt;code&gt;ossutil&lt;/code&gt;. This blog post will walk you through a common issue related to Alibaba Cloud’s Object Storage Service (OSS) and how to quickly resolve it by properly configuring your &lt;code&gt;ossutil&lt;/code&gt; tool.&lt;/p&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/categories/Cloud-Native/"/>
    
    <category term="Cloud Computing" scheme="https://cloudolife.com/categories/Cloud-Native/Cloud-Computing/"/>
    
    <category term="Alibaba Cloud" scheme="https://cloudolife.com/categories/Cloud-Native/Cloud-Computing/Alibaba-Cloud/"/>
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/tags/Cloud-Native/"/>
    
    <category term="Cloud Computing" scheme="https://cloudolife.com/tags/Cloud-Computing/"/>
    
    <category term="Object Storage Service (OSS)" scheme="https://cloudolife.com/tags/Object-Storage-Service-OSS/"/>
    
    <category term="Object Storage Service" scheme="https://cloudolife.com/tags/Object-Storage-Service/"/>
    
    <category term="OSS" scheme="https://cloudolife.com/tags/OSS/"/>
    
    <category term="ossutil" scheme="https://cloudolife.com/tags/ossutil/"/>
    
    <category term="ossutilconfig" scheme="https://cloudolife.com/tags/ossutilconfig/"/>
    
    <category term="Alibaba Cloud" scheme="https://cloudolife.com/tags/Alibaba-Cloud/"/>
    
  </entry>
  
  <entry>
    <title>[PostgreSQL] Resolving &quot;Permission Denied for Table&quot; Error in PostgreSQL pg_dump</title>
    <link href="https://cloudolife.com/2024/08/24/Awesome-Software/Development/Database/PostgreSQL/resolving-permission-denied-for-table-error-in-postgresql-pg-dump/"/>
    <id>https://cloudolife.com/2024/08/24/Awesome-Software/Development/Database/PostgreSQL/resolving-permission-denied-for-table-error-in-postgresql-pg-dump/</id>
    <published>2024-08-24T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.904Z</updated>
    
    <content type="html"><![CDATA[<h1>Resolving “Permission Denied for Table” Error in PostgreSQL pg_dump</h1><p>When managing PostgreSQL databases, one of the common tasks is creating backups using the <code>pg_dump</code> utility. However, you might encounter a frustrating error during this process, especially when your user lacks the necessary permissions. A common error looks like this:</p><span id="more"></span><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pg_dump -E UTF8 --username=&lt;user&gt; --dbname=&lt;db_name&gt; --compress=9 -f database.sql</span><br><span class="line"></span><br><span class="line">pg_dump: [archiver (db)] query failed: ERROR:  permission denied for table &lt;table_name&gt; </span><br><span class="line">pg_dump: [archiver (db)] query was: LOCK TABLE public.&lt;table_name&gt; IN ACCESS SHARE MODE</span><br></pre></td></tr></table></figure><p>This error indicates that the user performing the <code>pg_dump</code> operation does not have sufficient permissions on a specific table (<code>&lt;table_name&gt;</code>) in the database (<code>&lt;db_name&gt;</code>). Let’s explore why this happens and how to resolve it.</p><h2 id="Understanding-the-Issue">Understanding the Issue</h2><h3 id="Why-the-Error-Occurs">Why the Error Occurs</h3><p>In PostgreSQL, each table and database has an owner—typically the user who created them. The owner has full control over the table or database, including the ability to grant permissions to other users. When <code>pg_dump</code> tries to lock a table to ensure data consistency during the dump, it requires the user executing the command to have the appropriate permissions on the table.</p><p>If the user (<code>&lt;user&gt;</code>) is not the owner of the table or has not been granted sufficient privileges, PostgreSQL will deny the request, resulting in the “permission denied” error.</p><h3 id="Common-Scenario">Common Scenario</h3><p>This error often arises when:</p><ul><li>A new table (<code>&lt;table_name&gt;</code>) has been added to the database, and the user performing the <code>pg_dump</code> operation has not been granted access to it.</li><li>The user executing the dump is not the owner of the database or specific tables within the database.</li></ul><h2 id="Solutions">Solutions</h2><h3 id="1-Grant-Necessary-Permissions">1. Grant Necessary Permissions</h3><p>The quickest way to resolve this issue is to grant the user the necessary privileges on the table causing the problem. You can do this by executing the following SQL command:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="keyword">TABLE</span> public.<span class="operator">&lt;</span>table_name<span class="operator">&gt;</span> <span class="keyword">TO</span> <span class="operator">&lt;</span>db_user<span class="operator">&gt;</span>;</span><br></pre></td></tr></table></figure><p>Replace <code>&lt;table_name&gt;</code> with the actual name of the table and <code>&lt;db_user&gt;</code> with the username that needs the access. This command grants all privileges on the specified table to the user, allowing <code>pg_dump</code> to perform its operations without permission issues.</p><h3 id="2-Change-the-Ownership-of-the-Database">2. Change the Ownership of the Database</h3><p>If the user will regularly need to perform administrative tasks like backups, it might be more practical to change the ownership of the entire database to that user. This can be done with:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> DATABASE <span class="operator">&lt;</span>db_name<span class="operator">&gt;</span> OWNER <span class="keyword">TO</span> <span class="operator">&lt;</span>new_owner<span class="operator">&gt;</span>;</span><br></pre></td></tr></table></figure><p>Replace <code>&lt;db_name&gt;</code> with the name of your database and <code>&lt;new_owner&gt;</code> with the username that should become the new owner. With ownership, the user gains full control over all objects within the database, eliminating permission issues during tasks like <code>pg_dump</code>.</p><h2 id="Conclusion">Conclusion</h2><p>Permission errors during <code>pg_dump</code> can disrupt your database management workflow. By ensuring that your user has the necessary privileges or by transferring ownership of the database, you can avoid these issues and ensure smooth, uninterrupted backups.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Resolving “Permission Denied for Table” Error in PostgreSQL pg_dump&lt;/h1&gt;
&lt;p&gt;When managing PostgreSQL databases, one of the common tasks is creating backups using the &lt;code&gt;pg_dump&lt;/code&gt; utility. However, you might encounter a frustrating error during this process, especially when your user lacks the necessary permissions. A common error looks like this:&lt;/p&gt;</summary>
    
    
    
    <category term="Awesome Software" scheme="https://cloudolife.com/categories/Awesome-Software/"/>
    
    <category term="Database" scheme="https://cloudolife.com/categories/Awesome-Software/Database/"/>
    
    <category term="PostgreSQL" scheme="https://cloudolife.com/categories/Awesome-Software/Database/PostgreSQL/"/>
    
    
    <category term="PostgreSQL" scheme="https://cloudolife.com/tags/PostgreSQL/"/>
    
    <category term="Database" scheme="https://cloudolife.com/tags/Database/"/>
    
    <category term="Awesome Software" scheme="https://cloudolife.com/tags/Awesome-Software/"/>
    
    <category term="pg_dump" scheme="https://cloudolife.com/tags/pg-dump/"/>
    
    <category term="grant" scheme="https://cloudolife.com/tags/grant/"/>
    
  </entry>
  
  <entry>
    <title>[Ingress Nginx] Persisting Logs in Ingress Nginx</title>
    <link href="https://cloudolife.com/2024/07/06/Kubernetes-K8S/Ingress-Nginx/persisting-logs-in-ingress-nginx/"/>
    <id>https://cloudolife.com/2024/07/06/Kubernetes-K8S/Ingress-Nginx/persisting-logs-in-ingress-nginx/</id>
    <published>2024-07-06T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.920Z</updated>
    
    <content type="html"><![CDATA[<h1>Persisting Logs in Ingress Nginx</h1><p>When running an application at scale in a Kubernetes environment, logging is essential for monitoring, debugging, and auditing. Ingress Nginx, a popular ingress controller, plays a critical role in managing and routing traffic into your Kubernetes cluster. This article will walk you through how to persist logs in Ingress Nginx, including how to configure different types of logs such as controller logs, access logs, and error logs.</p><span id="more"></span><h2 id="Introduction">Introduction</h2><p>The logging in NGINX Ingress Controller consists of three main parts:</p><ol><li><p><strong>Controller Logs:</strong> These are the logs for the NGINX Ingress Controller itself. By default, these logs are output to <code>stdout</code>. However, you can configure them to be output to a file by using the <code>--log_dir</code> parameter during startup. If redirected to a file, the logs will automatically rotate but will not be cleaned up automatically.</p></li><li><p><strong>Access Logs:</strong> These logs record the incoming requests handled by NGINX. They are output to <code>stdout</code> by default but can be configured to output to a specific file through the NGINX configuration.</p></li><li><p><strong>Error Logs:</strong> These logs capture any errors that occur during the processing of requests. Like access logs, error logs are output to <code>stderr</code> by default but can also be redirected to a specific file.</p></li></ol><h2 id="Writing-Logs-to-Disk">Writing Logs to Disk</h2><p>To persist logs on the disk, follow these steps:</p><ol><li><p><strong>Create a Directory for Logs</strong></p><p>On the node where Ingress Nginx is running, create a directory for storing logs. Ensure that the directory has appropriate permissions.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -pv /var/lib/docker/nginxlogs/ingress</span><br><span class="line">chown -r 755:755 /var/lib/docker/nginxlogs/ingress</span><br></pre></td></tr></table></figure></li><li><p><strong>Configure the Controller Logs</strong></p><p>You can configure the Ingress Nginx Controller to output logs to a file by setting the <code>--log_dir</code> parameter. Here’s an example of how you can modify the controller’s arguments:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">args:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/nginx-ingress-controller</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--configmap=$(POD_NAMESPACE)/nginx-configuration</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--udp-services-configmap=$(POD_NAMESPACE)/udp-services</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--publish-service=$(POD_NAMESPACE)/ingress-nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--annotations-prefix=nginx.ingress.kubernetes.io</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--log_dir=/var/log/nginx/</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--logtostderr=false</span></span><br></pre></td></tr></table></figure></li><li><p><strong>Modify ConfigMap for Access and Error Logs</strong></p><p>Update the ConfigMap to define where access logs and error logs should be stored. You can also specify the format of these logs.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">worker-processes:</span> <span class="string">&quot;4&quot;</span></span><br><span class="line"><span class="attr">use-forwarded-headers:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">log-format-upstream:</span> <span class="string">&quot;[$host] [$remote_addr] [$http_x_forwarded_for] [$remote_user] [$time_local] [$request] [$status] [$body_bytes_sent] [$request_time] [$upstream_addr] [$upstream_response_time] [$connection] [$connection_requests] [$msec] [$uri] [$body_bytes_sent] [$http_referer] [$http_user_agent] [$request_length] [$http_session_id]&quot;</span></span><br><span class="line"><span class="attr">access-log-path:</span> <span class="string">&quot;/var/log/nginx/access.log&quot;</span></span><br><span class="line"><span class="attr">error-log-path:</span> <span class="string">&quot;/var/log/nginx/error.log&quot;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>Mount the Log Directory</strong></p><p>Finally, ensure that the logs are written to a persistent directory by mounting it within your pod configuration:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumeMounts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">localtime</span></span><br><span class="line">    <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/log/nginx</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">app-log</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">localtime</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app-log</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">&quot;/var/lib/docker/nginxlogs/ingress&quot;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="Example-Output">Example Output</h2><p>After implementing the above configuration, the logs should appear in the specified directory on the host. For example:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@ingress]# </span><span class="language-bash">ll</span></span><br><span class="line">total 12</span><br><span class="line">-rw-r--r-- 1 33 tape    0 March 23 09:25 access.log</span><br><span class="line">-rw-r--r-- 1 33 tape    0 March 23 09:25 error.log</span><br><span class="line">-rw-r--r-- 1 33 tape  265 March 23 09:25 nginx-ingress-controller.k8s-node-13.www-data.log.ERROR.20200423-092512.6</span><br><span class="line">-rw-r--r-- 1 33 tape 2996 March 23 09:25 nginx-ingress-controller.k8s-node-13.www-data.log.INFO.20200423-092510.6</span><br><span class="line">-rw-r--r-- 1 33 tape  543 March 23 09:25 nginx-ingress-controller.k8s-node-13.www-data.log.WARNING.20200423-092510.6</span><br><span class="line">lrwxrwxrwx 1 33 tape   82 March 23 09:25 nginx-ingress-controller.ERROR -&gt; nginx-ingress-controller.k8s-node-13.www-data.log.ERROR.20200323-092512.6</span><br><span class="line">lrwxrwxrwx 1 33 tape   81 March 23 09:25 nginx-ingress-controller.INFO -&gt; nginx-ingress-controller.k8s-node-13.www-data.log.INFO.20200323-092510.6</span><br><span class="line">lrwxrwxrwx 1 33 tape   84 March 23 09:25 nginx-ingress-controller.WARNING -&gt; nginx-ingress-controller.k8s-node-13.www-data.log.WARNING.20200323-092510.6</span><br></pre></td></tr></table></figure><h2 id="Domain-Specific-Access-Logs">Domain-Specific Access Logs</h2><p>If you wish to have logs that are specific to a domain, you can modify the Ingress resource directly. However, there is no global variable that allows automatic inclusion of the domain in logs. Here is how you can do it manually:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tomcat-test</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/enable-access-log:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/configuration-snippet:</span> <span class="string">|</span></span><br><span class="line"><span class="string">      access_log /var/log/nginx/test.cloudolife.com.log;</span></span><br><span class="line"><span class="string"></span><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">test.sy.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">tomcat-test</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">6080</span></span><br></pre></td></tr></table></figure><p>This configuration will create an access log specific to the <code>test.cloudolife.com</code> domain.</p><h2 id="Conclusion">Conclusion</h2><p>Persisting logs in Ingress Nginx involves configuring the controller, access logs, and error logs to write to specific files. This setup ensures that logs are not lost during pod restarts and can be retained for auditing and debugging purposes. While the default setup directs logs to stdout and stderr, configuring them to write to disk provides more control and persistence. If you’re dealing with multiple domains, consider manually setting up domain-specific access logs for better granularity.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Persisting Logs in Ingress Nginx&lt;/h1&gt;
&lt;p&gt;When running an application at scale in a Kubernetes environment, logging is essential for monitoring, debugging, and auditing. Ingress Nginx, a popular ingress controller, plays a critical role in managing and routing traffic into your Kubernetes cluster. This article will walk you through how to persist logs in Ingress Nginx, including how to configure different types of logs such as controller logs, access logs, and error logs.&lt;/p&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/categories/Cloud-Native/"/>
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/"/>
    
    <category term="Ingress Nginx" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/Ingress-Nginx/"/>
    
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/tags/Kubernetes-K8S/"/>
    
    <category term="Nginx" scheme="https://cloudolife.com/tags/Nginx/"/>
    
    <category term="Cloud Native" scheme="https://cloudolife.com/tags/Cloud-Native/"/>
    
    <category term="Helm" scheme="https://cloudolife.com/tags/Helm/"/>
    
    <category term="Logging" scheme="https://cloudolife.com/tags/Logging/"/>
    
    <category term="ConfigMap" scheme="https://cloudolife.com/tags/ConfigMap/"/>
    
    <category term="Ingress" scheme="https://cloudolife.com/tags/Ingress/"/>
    
    <category term="Ingress Nginx" scheme="https://cloudolife.com/tags/Ingress-Nginx/"/>
    
    <category term="Annotation" scheme="https://cloudolife.com/tags/Annotation/"/>
    
  </entry>
  
  <entry>
    <title>[Bundler] Enhancing Your Workflow with Bundler&#39;s Auto-Install</title>
    <link href="https://cloudolife.com/2024/06/30/Programming-Language/Ruby/Bundler/enhancing-your-workflow-with-bundlers-auto-install/"/>
    <id>https://cloudolife.com/2024/06/30/Programming-Language/Ruby/Bundler/enhancing-your-workflow-with-bundlers-auto-install/</id>
    <published>2024-06-30T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.938Z</updated>
    
    <content type="html"><![CDATA[<h1>Enhancing Your Workflow with Bundler’s Auto-Install</h1><p>Working in a large monolithic application often means dealing with frequent changes from multiple engineers. Every time you pull from <code>main</code>, you’re likely to encounter the familiar ritual of running <code>bundle install</code>, followed by <code>rails db:prepare</code> if you’re on a Rails application. Missing the <code>bundle install</code> step can lead to frustrating errors like:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Could not find X-1.2.3 in locally installed gems</span><br><span class="line">Run `bundle install` to install missing gems.</span><br></pre></td></tr></table></figure><p>With Bundler 2.5.10, there’s a game-changing update: the <code>auto_install</code> config. By setting this in your project or globally:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bundle config auto_install true</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">or</span></span><br><span class="line">bundle config --global auto_install true</span><br></pre></td></tr></table></figure><p>Bundler will automatically install missing gems on demand. While <code>auto_install</code> isn’t new, it now supports any command that uses <code>require &quot;bundler/setup&quot;</code>, including binstubs.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Enhancing Your Workflow with Bundler’s Auto-Install&lt;/h1&gt;
&lt;p&gt;Working in a large monolithic application often means dealing with frequent </summary>
      
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Ruby" scheme="https://cloudolife.com/categories/Programming-Language/Ruby/"/>
    
    <category term="Bundler" scheme="https://cloudolife.com/categories/Programming-Language/Ruby/Bundler/"/>
    
    
    <category term="Ruby" scheme="https://cloudolife.com/tags/Ruby/"/>
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="bundle" scheme="https://cloudolife.com/tags/bundle/"/>
    
    <category term="auto_install" scheme="https://cloudolife.com/tags/auto-install/"/>
    
    <category term="Bundler" scheme="https://cloudolife.com/tags/Bundler/"/>
    
  </entry>
  
  <entry>
    <title>[Kubernetes (K8S) Kubespray] Use Kubespray to add or remove control-plane,master node into the exist kubernetes (K8S) cluster</title>
    <link href="https://cloudolife.com/2024/06/01/Kubernetes-K8S/Loki-Stack/streamlining-kubernetes-logging-with-loki-and-promtail/"/>
    <id>https://cloudolife.com/2024/06/01/Kubernetes-K8S/Loki-Stack/streamlining-kubernetes-logging-with-loki-and-promtail/</id>
    <published>2024-06-01T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.921Z</updated>
    
    <content type="html"><![CDATA[<h1>Streamlining Kubernetes Logging with Loki and Promtail</h1><p>In the world of Kubernetes, efficient log management is crucial for maintaining and troubleshooting applications. Enter Loki and Promtail, a powerful duo that simplifies log collection and analysis in Kubernetes environments. This blog post will explore how to set up Promtail as a DaemonSet and configure it to work seamlessly with Loki.</p><span id="more"></span><h2 id="Promtail-DaemonSet-Capturing-Logs-Across-Your-Cluster">Promtail DaemonSet: Capturing Logs Across Your Cluster</h2><p>Promtail, the log collecting agent for Loki, can be deployed as a DaemonSet in Kubernetes. This ensures that Promtail runs on every node in your cluster, capturing logs from all your pods. Let’s look at a key part of the DaemonSet configuration:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/www/k8s/apps/logs</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        </span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">promtail</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/www/k8s/apps/logs</span></span><br></pre></td></tr></table></figure><p>This configuration mounts the host’s <code>/www/k8s/apps/logs</code> directory into the Promtail container. This allows Promtail to access and collect logs from applications that write to this directory on the host.</p><h2 id="Configuring-Loki-Promtail-Tailoring-Log-Collection">Configuring Loki Promtail : Tailoring Log Collection</h2><p>The heart of Promtail’s operation lies in its configuration. We typically manage this through a ConfigMap in Kubernetes. Here’s a snippet of a Promtail configuration:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">static_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/www/k8s/**/*.log</span></span><br><span class="line">    <span class="attr">targets:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">localhost</span></span><br></pre></td></tr></table></figure><p>This configuration tells Promtail to:</p><ol><li>Look for log files matching the pattern <code>/www/k8s/**/*.log</code></li><li>Label these logs with their file path</li><li>Consider ‘localhost’ as the target, which in this case refers to the node Promtail is running on</li></ol><h2 id="Why-This-Setup-Works">Why This Setup Works</h2><ol><li><strong>Comprehensive Coverage</strong>: By running Promtail as a DaemonSet, we ensure that logs from all nodes are collected.</li><li><strong>Flexibility</strong>: The use of a wildcard pattern in the log path allows Promtail to pick up logs from various applications without needing constant reconfiguration.</li><li><strong>Metadata Enrichment</strong>: By including the file path as a label, we maintain context about the log’s origin, which is crucial for analysis in Loki.</li></ol><h2 id="Conclusion">Conclusion</h2><p>This setup provides a robust foundation for log collection in a Kubernetes environment. By leveraging Promtail’s capabilities and Kubernetes’ native concepts like DaemonSets and ConfigMaps, we create a system that’s both powerful and adaptable to changing logging needs.</p><p>Remember, effective log management is key to maintaining healthy, observable Kubernetes applications. With Loki and Promtail, you’re well on your way to achieving this goal.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Streamlining Kubernetes Logging with Loki and Promtail&lt;/h1&gt;
&lt;p&gt;In the world of Kubernetes, efficient log management is crucial for maintaining and troubleshooting applications. Enter Loki and Promtail, a powerful duo that simplifies log collection and analysis in Kubernetes environments. This blog post will explore how to set up Promtail as a DaemonSet and configure it to work seamlessly with Loki.&lt;/p&gt;</summary>
    
    
    
    <category term="Cloud Native" scheme="https://cloudolife.com/categories/Cloud-Native/"/>
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/"/>
    
    <category term="Loki-Stack" scheme="https://cloudolife.com/categories/Cloud-Native/Kubernetes-K8S/Loki-Stack/"/>
    
    
    <category term="Kubernetes (K8S)" scheme="https://cloudolife.com/tags/Kubernetes-K8S/"/>
    
    <category term="Cloud Native" scheme="https://cloudolife.com/tags/Cloud-Native/"/>
    
    <category term="Loki" scheme="https://cloudolife.com/tags/Loki/"/>
    
    <category term="loki-promtail" scheme="https://cloudolife.com/tags/loki-promtail/"/>
    
    <category term="Promtail" scheme="https://cloudolife.com/tags/Promtail/"/>
    
    <category term="Loki-Stack" scheme="https://cloudolife.com/tags/Loki-Stack/"/>
    
  </entry>
  
  <entry>
    <title>[APT] Resolving 404 Errors with Debian Jessie Repositories on Aliyun Mirrors</title>
    <link href="https://cloudolife.com/2023/12/02/Linux/Debian/APT/resolving-404-errors-with-debian-jessie-repositories-on-aliyun-mirrors/"/>
    <id>https://cloudolife.com/2023/12/02/Linux/Debian/APT/resolving-404-errors-with-debian-jessie-repositories-on-aliyun-mirrors/</id>
    <published>2023-12-02T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.922Z</updated>
    
    <content type="html"><![CDATA[<h1>Resolving 404 Errors with Debian Jessie Repositories on Aliyun Mirrors</h1><p>If you’ve been managing Debian servers, especially those running the older Jessie distribution, you might have encountered a frustrating 404 Not Found error when trying to fetch updates from Aliyun mirrors. This error typically looks something like this:</p><span id="more"></span><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http://mirrors.aliyun.com/debian-security/dists/jessie/updates/main/binary-amd64/Packages 404 Not Found [IP: 27.221.82.230 80]</span><br><span class="line">W: Failed to fetch</span><br></pre></td></tr></table></figure><p>This issue arises because Debian Jessie has reached its end of life, and its packages are no longer hosted in the primary repositories. Instead, they have been moved to the Debian Archive repositories. Fortunately, resolving this issue is straightforward.</p><h2 id="Updating-Your-Sources-List">Updating Your Sources List</h2><p>To fix the 404 error and ensure your system can still access Jessie packages and security updates, you need to update the <code>/etc/apt/sources.list</code> file to point to the correct archive locations.</p><p>Here’s the initial, problematic configuration:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;deb http://mirrors.aliyun.com/debian/ jessie main non-free contrib&quot; &gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb http://mirrors.aliyun.com/debian-security/ jessie/updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb-src http://mirrors.aliyun.com/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb-src http://mirrors.aliyun.com/debian-security/ jessie/updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br></pre></td></tr></table></figure><p>This configuration fails because the primary and security repositories for Jessie have been archived. You need to update your sources to point to the Debian Archive repositories instead.</p><h2 id="Correct-Configuration">Correct Configuration</h2><p>To ensure your system points to the correct repositories, update your <code>/etc/apt/sources.list</code> as follows:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;deb http://mirrors.aliyun.com/debian-archive/debian/ jessie main non-free contrib&quot; &gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb http://mirrors.aliyun.com/debian-archive/debian-security/ jessie/updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb-src http://mirrors.aliyun.com/debian-archive/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb-src http://mirrors.aliyun.com/debian-archive/debian-security/ jessie/updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br></pre></td></tr></table></figure><h2 id="Step-by-Step-Guide">Step-by-Step Guide</h2><ol><li><p><strong>Open Terminal:</strong><br>Open a terminal on your Debian Jessie system.</p></li><li><p><strong>Edit Sources List:</strong><br>Run the following commands to overwrite the existing sources list with the updated entries:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;deb http://mirrors.aliyun.com/debian-archive/debian/ jessie main non-free contrib&quot; &gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb http://mirrors.aliyun.com/debian-archive/debian-security/ jessie/updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb-src http://mirrors.aliyun.com/debian-archive/debian/ jessie main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    echo &quot;deb-src http://mirrors.aliyun.com/debian-archive/debian-security/ jessie/updates main non-free contrib&quot; &gt;&gt;/etc/apt/sources.list &amp;&amp; \</span><br></pre></td></tr></table></figure></li><li><p><strong>Update Package Lists:</strong><br>Update your package lists to reflect the new repository locations:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></li><li><p><strong>Install or Upgrade Packages:</strong><br>You can now install or upgrade packages as needed without encountering the 404 error.</p></li></ol><h2 id="Conclusion">Conclusion</h2><p>By pointing your Debian Jessie system to the correct archive repositories on Aliyun, you can continue to manage your packages without interruption. Although Jessie is an older release, many systems still rely on it, and understanding how to properly maintain these systems is crucial for any Debian administrator. This quick adjustment ensures that your package management continues smoothly, even after the official end-of-life of Jessie.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Resolving 404 Errors with Debian Jessie Repositories on Aliyun Mirrors&lt;/h1&gt;
&lt;p&gt;If you’ve been managing Debian servers, especially those running the older Jessie distribution, you might have encountered a frustrating 404 Not Found error when trying to fetch updates from Aliyun mirrors. This error typically looks something like this:&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://cloudolife.com/categories/Linux/"/>
    
    <category term="Debian" scheme="https://cloudolife.com/categories/Linux/Debian/"/>
    
    <category term="APT" scheme="https://cloudolife.com/categories/Linux/Debian/APT/"/>
    
    
    <category term="Linux" scheme="https://cloudolife.com/tags/Linux/"/>
    
    <category term="Aliyun" scheme="https://cloudolife.com/tags/Aliyun/"/>
    
    <category term="Jessie" scheme="https://cloudolife.com/tags/Jessie/"/>
    
    <category term="apt-get" scheme="https://cloudolife.com/tags/apt-get/"/>
    
    <category term="Debian" scheme="https://cloudolife.com/tags/Debian/"/>
    
    <category term="APT" scheme="https://cloudolife.com/tags/APT/"/>
    
  </entry>
  
  <entry>
    <title>[APT] Resolving APT Installation Issues with --allow-unauthenticated</title>
    <link href="https://cloudolife.com/2023/12/02/Linux/Debian/APT/resolving-apt-installation-issues-with-allow-unauthenticated/"/>
    <id>https://cloudolife.com/2023/12/02/Linux/Debian/APT/resolving-apt-installation-issues-with-allow-unauthenticated/</id>
    <published>2023-12-02T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.922Z</updated>
    
    <content type="html"><![CDATA[<h1>Resolving APT Installation Issues with --allow-unauthenticated</h1><p>When managing packages on Debian-based systems, APT (<code>apt-get</code>) is a powerful tool that ensures installations are secure and reliable. However, there are instances where you might encounter issues during package installation, especially when using the <code>-y</code> flag for automatic confirmation without manual intervention.</p><span id="more"></span><p>Consider the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y build-essential openssh-server git libpq-dev nodejs curl cron</span><br></pre></td></tr></table></figure><p>While <code>-y</code> automatically answers “yes” to prompts, it doesn’t address all potential issues. Sometimes, APT might flag certain packages as unauthenticated, causing the installation to fail. This is where the <code>--allow-unauthenticated</code> flag becomes useful.</p><p>By appending <code>--allow-unauthenticated</code>, you permit the installation of packages even if their authenticity cannot be verified. Here’s how you modify the command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y --allow-unauthenticated build-essential openssh-server git libpq-dev nodejs curl cron</span><br></pre></td></tr></table></figure><p>This adjustment ensures that all specified packages are installed, bypassing the authenticity check. While this approach can be a quick fix, it is important to use it cautiously. Installing unauthenticated packages can pose security risks, as it potentially allows the inclusion of malicious software.</p><p>For production environments, it’s advisable to identify the root cause of authentication issues and resolve them by adding the appropriate GPG keys or verifying repository sources. This ensures a balance between smooth installations and maintaining system security.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Resolving APT Installation Issues with --allow-unauthenticated&lt;/h1&gt;
&lt;p&gt;When managing packages on Debian-based systems, APT (&lt;code&gt;apt-get&lt;/code&gt;) is a powerful tool that ensures installations are secure and reliable. However, there are instances where you might encounter issues during package installation, especially when using the &lt;code&gt;-y&lt;/code&gt; flag for automatic confirmation without manual intervention.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://cloudolife.com/categories/Linux/"/>
    
    <category term="Debian" scheme="https://cloudolife.com/categories/Linux/Debian/"/>
    
    <category term="APT" scheme="https://cloudolife.com/categories/Linux/Debian/APT/"/>
    
    
    <category term="Linux" scheme="https://cloudolife.com/tags/Linux/"/>
    
    <category term="apt-get" scheme="https://cloudolife.com/tags/apt-get/"/>
    
    <category term="Debian" scheme="https://cloudolife.com/tags/Debian/"/>
    
    <category term="APT" scheme="https://cloudolife.com/tags/APT/"/>
    
  </entry>
  
  <entry>
    <title>[Awesome Ruby Gem] Creating a Rails App with React by jsbundling-rails Gem</title>
    <link href="https://cloudolife.com/2023/11/04/Programming-Language/Ruby/Awesome-Ruby-Gem/jsbundling-rails/creating-a-rails-app-with-react-by-jsbundling-rails-gem/"/>
    <id>https://cloudolife.com/2023/11/04/Programming-Language/Ruby/Awesome-Ruby-Gem/jsbundling-rails/creating-a-rails-app-with-react-by-jsbundling-rails-gem/</id>
    <published>2023-11-04T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.938Z</updated>
    
    <content type="html"><![CDATA[<h1>Creating a Rails App with React by jsbundling-rails Gem</h1><p>Ruby on Rails is a robust web application framework that simplifies the creation of complex web applications. One of the recent additions to the Rails ecosystem is the <code>jsbundling-rails</code> gem, which provides a streamlined way to manage JavaScript bundling with tools like Esbuild. In this blog, we’ll walk through setting up a new Rails application with the <code>jsbundling-rails</code> gem, configuring Esbuild, and integrating popular JavaScript libraries React.</p><span id="more"></span><p>Before you begin, make sure you have Node.js and NPX installed on your system. You can download and install them from the <a href="https://nodejs.org/">Node.js website</a>.</p><p>Verify the installation by running:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line"></span><br><span class="line">npx -v</span><br></pre></td></tr></table></figure><h2 id="Step-1-Create-a-New-Rails-Application">Step 1: Create a New Rails Application</h2><p>First, ensure you have Rails installed on your system. Then, create a new Rails application with Esbuild as the JavaScript bundler:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rails new my-rails-app -j esbuild</span><br></pre></td></tr></table></figure><p>This command initializes a new Rails app named <code>my-rails-app</code> with Esbuild for JavaScript bundling. You’ll see a series of files and directories created as part of the app setup.</p><h2 id="Step-2-Install-Dependencies">Step 2: Install Dependencies</h2><p>Navigate to your new app directory and install the necessary gems and JavaScript packages:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd my-rails-app</span><br><span class="line">bundle install</span><br></pre></td></tr></table></figure><p>Next, install the Esbuild bundler and other JavaScript dependencies using Yarn:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn add esbuild</span><br></pre></td></tr></table></figure><p>Alternatively, if you prefer using <code>pnpm</code>, install <code>pnpm</code> globally and use it to manage your packages:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install -g pnpm</span><br><span class="line"></span><br><span class="line">pnpm install</span><br></pre></td></tr></table></figure><h2 id="Step-3-Configure-JavaScript-Bundling">Step 3: Configure JavaScript Bundling</h2><p>Rails provides a default configuration for Esbuild, but you may want to customize it. Create an <code>esbuild.config.mjs</code> file in the root of your project with the following content:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> entryPoints = [</span><br><span class="line">    <span class="string">&quot;application.js&quot;</span>,</span><br><span class="line">    <span class="string">&quot;administrate.js&quot;</span>,</span><br><span class="line">    <span class="string">&quot;react.tsx&quot;</span></span><br><span class="line">];</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> watchDirectories = [</span><br><span class="line">  <span class="string">&quot;./app/javascript/**/*.&#123;js,ts,tsx,jsx&#125;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;./app/views/**/*.html.erb&quot;</span>,</span><br><span class="line">  <span class="string">&quot;./app/assets/builds/**/*.css&quot;</span>, <span class="comment">// Wait for cssbundling changes</span></span><br><span class="line">  <span class="string">&quot;./config/locales/**/*.yml&quot;</span>,</span><br><span class="line">];</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> &#123; entryPoints, watchDirectories &#125;;</span><br></pre></td></tr></table></figure><p>This configuration specifies the entry points for your JavaScript files and directories to watch for changes.</p><h2 id="Step-4-Integrate-React-and-TypeScript">Step 4: Integrate React and TypeScript</h2><p>To add React and TypeScript support, install the necessary packages:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pnpm add react react-dom @types/react @types/react-dom typescript</span><br></pre></td></tr></table></figure><p>Next, create a <code>tsconfig.json</code> file in the root of your project to configure TypeScript:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;compilerOptions&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;commonjs&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;esModuleInterop&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;forceConsistentCasingInFileNames&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;strict&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;skipLibCheck&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;jsx&quot;</span><span class="punctuation">:</span> <span class="string">&quot;react&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>This configuration enables TypeScript with JSX support for React.</p><h2 id="Step-5-Configure-Stimulus-and-Turbo">Step 5: Configure Stimulus and Turbo</h2><p>Rails 7 integrates seamlessly with Hotwire, which includes Turbo and Stimulus. Install these libraries using <code>pnpm</code>:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pnpm add @hotwired/stimulus @hotwired/turbo-rails</span><br></pre></td></tr></table></figure><p>Update your JavaScript entry point (<code>app/javascript/application.js</code>) to include Turbo and Stimulus:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Turbo</span> &#125; <span class="keyword">from</span> <span class="string">&quot;@hotwired/turbo-rails&quot;</span></span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Application</span> &#125; <span class="keyword">from</span> <span class="string">&quot;stimulus&quot;</span></span><br><span class="line"><span class="keyword">import</span> &#123; definitionsFromContext &#125; <span class="keyword">from</span> <span class="string">&quot;stimulus/webpack-helpers&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> application = <span class="title class_">Application</span>.<span class="title function_">start</span>()</span><br><span class="line"><span class="keyword">const</span> context = <span class="built_in">require</span>.<span class="title function_">context</span>(<span class="string">&quot;./controllers&quot;</span>, <span class="literal">true</span>, <span class="regexp">/\.js$/</span>)</span><br><span class="line">application.<span class="title function_">load</span>(<span class="title function_">definitionsFromContext</span>(context))</span><br></pre></td></tr></table></figure><h2 id="Step-6-Run-the-Server">Step 6: Run the Server</h2><p>With everything set up, start the Rails development server and the JavaScript bundler:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/rails s</span><br><span class="line"></span><br><span class="line">yarn build --watch</span><br></pre></td></tr></table></figure><p>The <code>bin/rails</code> script runs the Rails server and the <code>yarn build --watch</code> runs Esbuild watcher concurrently, ensuring your changes are reflected immediately.</p><h2 id="Conclusion">Conclusion</h2><p>By following these steps, you have successfully created a new Rails application using the <code>jsbundling-rails</code> gem with Esbuild. You’ve also integrated React, TypeScript, Turbo, and Stimulus into your Rails app, providing a modern and efficient development environment. This setup not only simplifies JavaScript bundling but also enhances your development workflow with powerful tools and libraries.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Creating a Rails App with React by jsbundling-rails Gem&lt;/h1&gt;
&lt;p&gt;Ruby on Rails is a robust web application framework that simplifies the creation of complex web applications. One of the recent additions to the Rails ecosystem is the &lt;code&gt;jsbundling-rails&lt;/code&gt; gem, which provides a streamlined way to manage JavaScript bundling with tools like Esbuild. In this blog, we’ll walk through setting up a new Rails application with the &lt;code&gt;jsbundling-rails&lt;/code&gt; gem, configuring Esbuild, and integrating popular JavaScript libraries React.&lt;/p&gt;</summary>
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Ruby" scheme="https://cloudolife.com/categories/Programming-Language/Ruby/"/>
    
    <category term="Awesome Ruby Gem" scheme="https://cloudolife.com/categories/Programming-Language/Ruby/Awesome-Ruby-Gem/"/>
    
    
    <category term="Ruby" scheme="https://cloudolife.com/tags/Ruby/"/>
    
    <category term="Node.js" scheme="https://cloudolife.com/tags/Node-js/"/>
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="npm" scheme="https://cloudolife.com/tags/npm/"/>
    
    <category term="yarn" scheme="https://cloudolife.com/tags/yarn/"/>
    
    <category term="npx" scheme="https://cloudolife.com/tags/npx/"/>
    
    <category term="pnpm" scheme="https://cloudolife.com/tags/pnpm/"/>
    
    <category term="RubyGems.org" scheme="https://cloudolife.com/tags/RubyGems-org/"/>
    
    <category term="Awesome Ruby Gem" scheme="https://cloudolife.com/tags/Awesome-Ruby-Gem/"/>
    
    <category term="React" scheme="https://cloudolife.com/tags/React/"/>
    
    <category term="jsbundling-rails" scheme="https://cloudolife.com/tags/jsbundling-rails/"/>
    
    <category term="esbuild" scheme="https://cloudolife.com/tags/esbuild/"/>
    
  </entry>
  
  <entry>
    <title>[Awesome Ruby Gem] Managing Bootsnap Cache in Rails: Troubleshooting Common Issues</title>
    <link href="https://cloudolife.com/2023/10/14/Programming-Language/Ruby/Awesome-Ruby-Gem/Bootsnap/managing-bootsnap-cache-in-rails-troubleshooting-common-issues/"/>
    <id>https://cloudolife.com/2023/10/14/Programming-Language/Ruby/Awesome-Ruby-Gem/Bootsnap/managing-bootsnap-cache-in-rails-troubleshooting-common-issues/</id>
    <published>2023-10-14T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.933Z</updated>
    
    <content type="html"><![CDATA[<h1>Managing Bootsnap Cache in Rails: Troubleshooting Common Issues</h1><p>When working with Ruby on Rails applications, optimizing performance and ensuring smooth deployments are paramount. One powerful tool in the Rails ecosystem for speeding up boot times is <a href="https://github.com/Shopify/bootsnap">Bootsnap</a>, which caches expensive computations and can significantly reduce application startup times. However, like any caching mechanism, it can sometimes cause issues that developers need to address. In this blog post, we’ll explore a common issue related to Bootsnap caching and how to resolve it effectively.</p><span id="more"></span><h2 id="Understanding-the-Issue-belongs-to-Not-Working-After-Column-Type-Change">Understanding the Issue: <code>belongs_to</code> Not Working After Column Type Change</h2><p>Imagine you have a Rails application with a <code>Patient</code> model that belongs to a <code>Department</code>. The association is defined as follows:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Patient</span> &lt; <span class="title class_ inherited__">ApplicationRecord</span></span><br><span class="line">  belongs_to <span class="symbol">:department</span>, <span class="symbol">optional:</span> <span class="literal">true</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>You try to access the department of the last patient in the database:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title class_">Patient</span>.last.department</span><br></pre></td></tr></table></figure><p>But instead of getting the department, you encounter an error:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">undefined method <span class="string">&#x27;department&#x27;</span> <span class="keyword">for</span> #&lt;Patient:0x00007f78ff60918&gt;</span><br><span class="line"><span class="title class_">Did</span> you mean? department_id</span><br></pre></td></tr></table></figure><p>This issue often arises after changing the type of the reference column (<code>department_id</code>) in the database. Even though the migration might have run successfully, the Rails application does not recognize the association, leading to the above error.</p><h2 id="The-Role-of-Bootsnap-Cache">The Role of Bootsnap Cache</h2><p>Bootsnap caches various elements of the application to improve performance, including method definitions and ActiveRecord associations. When you change the type of a reference column, these cached definitions might not get updated immediately, leading to the observed error.</p><h2 id="Solution-Clearing-the-Bootsnap-Cache">Solution: Clearing the Bootsnap Cache</h2><p>To resolve this issue, you need to clear the Bootsnap cache so that the application can reload the updated definitions. This can be done by removing the cached files in the <code>tmp/cache/</code> directory. Execute the following command in your terminal:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -fr tmp/cache/</span><br></pre></td></tr></table></figure><p>By removing these cache files, you force Rails to rebuild the cache with the updated column definitions and associations. This should resolve the <code>undefined method 'department'</code> error.</p><h2 id="Proactive-Cache-Management">Proactive Cache Management</h2><h3 id="Periodic-Cache-Cleanup">Periodic Cache Cleanup</h3><p>Bootsnap does not automatically clean up its cache, which means that over time, the cache can grow and potentially slow down your deployments. Depending on your deployment strategy, you might need to periodically purge the <code>tmp/cache/bootsnap*</code> files to maintain optimal performance. For instance, you can add a cleanup step in your deployment script:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -fr tmp/cache/bootsnap*</span><br></pre></td></tr></table></figure><p>Regularly clearing the Bootsnap cache can help prevent issues related to stale or outdated cache data, ensuring that your application continues to run smoothly.</p><h3 id="Deployment-Considerations">Deployment Considerations</h3><p>If you notice that your deployments are progressively getting slower, it’s almost certainly due to the growing Bootsnap cache. Incorporating a cache cleanup step in your deployment process can help mitigate this issue. For example, in a Capistrano deployment script, you could add a task to clear the cache:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">namespace <span class="symbol">:deploy</span> <span class="keyword">do</span></span><br><span class="line">  desc <span class="string">&#x27;Clear Bootsnap cache&#x27;</span></span><br><span class="line">  task <span class="symbol">:clear_bootsnap_cache</span> <span class="keyword">do</span></span><br><span class="line">    on roles(<span class="symbol">:app</span>) <span class="keyword">do</span></span><br><span class="line">      execute <span class="symbol">:rm</span>, <span class="string">&#x27;-fr&#x27;</span>, release_path.join(<span class="string">&#x27;tmp/cache/bootsnap*&#x27;</span>)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  before <span class="string">&#x27;deploy:restart&#x27;</span>, <span class="string">&#x27;deploy:clear_bootsnap_cache&#x27;</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>By adding such a task, you ensure that each deployment starts with a clean cache, reducing the risk of cache-related issues.</p><h2 id="Conclusion">Conclusion</h2><p>Bootsnap is a valuable tool for improving the performance of Ruby on Rails applications, but it requires proper management to avoid potential issues. When encountering problems like the <code>belongs_to</code> association not working after a column type change, clearing the Bootsnap cache is a quick and effective solution. Additionally, incorporating regular cache cleanup in your deployment process can help maintain optimal performance and prevent deployment slowdowns. By understanding and managing Bootsnap’s cache, you can ensure a smoother and more reliable Rails development experience.</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Managing Bootsnap Cache in Rails: Troubleshooting Common Issues&lt;/h1&gt;
&lt;p&gt;When working with Ruby on Rails applications, optimizing performance and ensuring smooth deployments are paramount. One powerful tool in the Rails ecosystem for speeding up boot times is &lt;a href=&quot;https://github.com/Shopify/bootsnap&quot;&gt;Bootsnap&lt;/a&gt;, which caches expensive computations and can significantly reduce application startup times. However, like any caching mechanism, it can sometimes cause issues that developers need to address. In this blog post, we’ll explore a common issue related to Bootsnap caching and how to resolve it effectively.&lt;/p&gt;</summary>
    
    
    
    <category term="Programming Language" scheme="https://cloudolife.com/categories/Programming-Language/"/>
    
    <category term="Ruby" scheme="https://cloudolife.com/categories/Programming-Language/Ruby/"/>
    
    <category term="Awesome Ruby Gem" scheme="https://cloudolife.com/categories/Programming-Language/Ruby/Awesome-Ruby-Gem/"/>
    
    
    <category term="Ruby" scheme="https://cloudolife.com/tags/Ruby/"/>
    
    <category term="Programming Language" scheme="https://cloudolife.com/tags/Programming-Language/"/>
    
    <category term="Gem" scheme="https://cloudolife.com/tags/Gem/"/>
    
    <category term="RubyGems.org" scheme="https://cloudolife.com/tags/RubyGems-org/"/>
    
    <category term="Awesome Ruby Gem" scheme="https://cloudolife.com/tags/Awesome-Ruby-Gem/"/>
    
    <category term="Bootsnap" scheme="https://cloudolife.com/tags/Bootsnap/"/>
    
  </entry>
  
  <entry>
    <title>[Infrastructure as Code (IaC)] How to Install and Register GitLab Runner and Shell Executor on CentOS</title>
    <link href="https://cloudolife.com/2023/10/07/DevOps/GitLab/GitLab-Runner/how-to-install-and-register-gitlab-runner-and-shell-executor-on-centos/"/>
    <id>https://cloudolife.com/2023/10/07/DevOps/GitLab/GitLab-Runner/how-to-install-and-register-gitlab-runner-and-shell-executor-on-centos/</id>
    <published>2023-10-07T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.913Z</updated>
    
    <content type="html"><![CDATA[<h1>How to Install and Register GitLab Runner and Shell Executor on CentOS</h1><p>In today’s DevOps landscape, continuous integration and continuous delivery (CI/CD) pipelines are essential for delivering high-quality software. GitLab Runner, a tool used to run jobs in a GitLab CI/CD pipeline, is an integral part of this process. This guide will walk you through installing and registering GitLab Runner on CentOS, ensuring you have a reliable setup for your development workflow.</p><span id="more"></span><h2 id="Prerequisites">Prerequisites</h2><p>Before you begin, ensure you have:</p><ul><li>A CentOS system (version 7 or later)</li><li>Root or sudo access to the system</li><li>A GitLab instance and a registration token for the runner</li></ul><h2 id="Step-1-Add-the-Official-GitLab-Repository">Step 1: Add the Official GitLab Repository</h2><p>The first step is to add the official GitLab repository to your system. This repository contains the latest version of GitLab Runner and ensures that you get updates directly from GitLab.</p><p>Open your terminal and run the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -L &quot;https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh&quot; | sudo bash`</span><br></pre></td></tr></table></figure><p>This command downloads and executes a script that adds the GitLab repository to your system.</p><h2 id="Step-2-Install-GitLab-Runner">Step 2: Install GitLab Runner</h2><p>Once the repository is added, you can install GitLab Runner using the <code>yum</code> package manager. Run the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install gitlab-runner</span><br></pre></td></tr></table></figure><p>This command installs the GitLab Runner package and its dependencies on your CentOS system.</p><h2 id="Step-3-Register-GitLab-Runner">Step 3: Register GitLab Runner</h2><p>After installing GitLab Runner, the next step is to register it with your GitLab instance. This process links the runner to your GitLab projects, allowing it to execute CI/CD jobs.</p><p>Run the following command to start the registration process:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner register</span><br></pre></td></tr></table></figure><p>You will be prompted to enter several pieces of information during the registration process:</p><ol><li><strong>GitLab instance URL</strong>: Enter the URL of your GitLab instance (e.g., <code>https://gitlab.com/</code> or your self-hosted GitLab URL).</li><li><strong>Registration token</strong>: Enter the registration token provided by your GitLab instance.</li><li><strong>Description</strong>: Provide a description for the runner to help identify it in the GitLab interface.</li><li><strong>Tags</strong>: Enter tags for the runner, separated by commas. These tags are used to match jobs with runners.</li><li><strong>Executor</strong>: Choose the executor for the runner. For this guide, we’ll use <code>shell</code>.</li></ol><p>An example registration session might look like this:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Runtime platform                                    arch=amd64 os=linux pid=7947 revision=44feccdf version=17.0.0</span><br><span class="line">Running in system-mode.</span><br><span class="line"></span><br><span class="line">Enter the GitLab instance URL (for example, https://gitlab.com/):  </span><br><span class="line">https://xx.xxx.xxx/  </span><br><span class="line">Enter the registration token:</span><br><span class="line">xxxxxxxxxx</span><br><span class="line">Enter a description for the runner:</span><br><span class="line">[xxxx]: xxx</span><br><span class="line">Enter tags for the runner (comma-separated):</span><br><span class="line">xxx</span><br><span class="line">Enter optional maintenance note for the runner:</span><br><span class="line"></span><br><span class="line">Registering runner... succeeded                     runner=DAM2LCZd</span><br><span class="line">Enter an executor: custom, parallels, docker, docker+machine, kubernetes, instance, shell, ssh, virtualbox, docker-windows, docker-autoscaler:</span><br><span class="line">shell</span><br><span class="line">Runner registered successfully. Feel free to start it, but if it&#x27;s running already the config should be automatically reloaded!</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>After successful registration, the configuration is saved in <code>/etc/gitlab-runner/config.toml</code>.</p><h2 id="Step-4-Start-GitLab-Runner">Step 4: Start GitLab Runner</h2><p>Once the runner is registered, you can start it using the following command:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-runner start</span><br></pre></td></tr></table></figure><p>This command starts the GitLab Runner service, allowing it to pick up and execute jobs from your GitLab instance.</p><h2 id="Conclusion">Conclusion</h2><p>By following these steps, you have successfully installed and registered GitLab Runner on your CentOS system. This setup allows you to leverage GitLab’s powerful CI/CD capabilities, automating your build, test, and deployment processes. For more detailed information and advanced configurations, refer to the <a href="https://docs.gitlab.com/runner/install/linux-repository.html">official GitLab documentation</a>.</p><p>Happy building!</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;How to Install and Register GitLab Runner and Shell Executor on CentOS&lt;/h1&gt;
&lt;p&gt;In today’s DevOps landscape, continuous integration and continuous delivery (CI/CD) pipelines are essential for delivering high-quality software. GitLab Runner, a tool used to run jobs in a GitLab CI/CD pipeline, is an integral part of this process. This guide will walk you through installing and registering GitLab Runner on CentOS, ensuring you have a reliable setup for your development workflow.&lt;/p&gt;</summary>
    
    
    
    <category term="Infrastructure as Code (IaC)" scheme="https://cloudolife.com/categories/Infrastructure-as-Code-IaC/"/>
    
    <category term="GitLab" scheme="https://cloudolife.com/categories/Infrastructure-as-Code-IaC/GitLab/"/>
    
    <category term="GitLab Runner" scheme="https://cloudolife.com/categories/Infrastructure-as-Code-IaC/GitLab/GitLab-Runner/"/>
    
    
    <category term="GitLab" scheme="https://cloudolife.com/tags/GitLab/"/>
    
    <category term="CI" scheme="https://cloudolife.com/tags/CI/"/>
    
    <category term="CD" scheme="https://cloudolife.com/tags/CD/"/>
    
    <category term="Infrastructure" scheme="https://cloudolife.com/tags/Infrastructure/"/>
    
    <category term="Continuous" scheme="https://cloudolife.com/tags/Continuous/"/>
    
    <category term="Integration" scheme="https://cloudolife.com/tags/Integration/"/>
    
    <category term="(CI)" scheme="https://cloudolife.com/tags/CI/"/>
    
    <category term="Delivery" scheme="https://cloudolife.com/tags/Delivery/"/>
    
    <category term="(CD)" scheme="https://cloudolife.com/tags/CD/"/>
    
    <category term="as" scheme="https://cloudolife.com/tags/as/"/>
    
    <category term="Code" scheme="https://cloudolife.com/tags/Code/"/>
    
    <category term="(IaC)" scheme="https://cloudolife.com/tags/IaC/"/>
    
    <category term="Runner" scheme="https://cloudolife.com/tags/Runner/"/>
    
    <category term="Pipeline" scheme="https://cloudolife.com/tags/Pipeline/"/>
    
    <category term="Trigger" scheme="https://cloudolife.com/tags/Trigger/"/>
    
    <category term="Job" scheme="https://cloudolife.com/tags/Job/"/>
    
  </entry>
  
  <entry>
    <title>[Infrastructure as Code (IaC)] Troubleshooting Common Issues with GitLab Runner Shell Executor on CentOS</title>
    <link href="https://cloudolife.com/2023/10/07/DevOps/GitLab/GitLab-Runner/troubleshooting-common-issues-with-gitlab-runner-shell-executor-on-centos/"/>
    <id>https://cloudolife.com/2023/10/07/DevOps/GitLab/GitLab-Runner/troubleshooting-common-issues-with-gitlab-runner-shell-executor-on-centos/</id>
    <published>2023-10-07T00:00:00.000Z</published>
    <updated>2025-06-10T09:49:34.913Z</updated>
    
    <content type="html"><![CDATA[<h1>Troubleshooting Common Issues with GitLab Runner Shell Executor on CentOS</h1><p>As a senior software engineer, I often encounter various challenges while working with GitLab Runner on CentOS. This blog post aims to address some common issues and provide solutions that can help streamline your CI/CD pipeline. Whether you’re upgrading Git, managing permissions for Docker, or dealing with runtime errors, this guide will offer practical steps to resolve these issues efficiently.</p><span id="more"></span><h2 id="1-Fatal-Error-git-fetch-pack-expected-shallow-list">1. Fatal Error: <code>git fetch-pack: expected shallow list</code></h2><h3 id="Issue">Issue:</h3><p>When running your GitLab CI/CD pipeline, you might encounter the following error:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fatal: git fetch-pack: expected shallow list</span><br></pre></td></tr></table></figure><h3 id="Solution">Solution:</h3><p>This issue often arises due to an outdated version of Git. To resolve it, upgrade Git to the latest version.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install http://opensource.wandisco.com/centos/7/git/x86_64/wandisco-git-release-7-2.noarch.rpm</span><br><span class="line"></span><br><span class="line">yum upgrade git -y</span><br></pre></td></tr></table></figure><h2 id="2-Permission-Denied-Docker-Daemon-Socket">2. Permission Denied: Docker Daemon Socket</h2><h3 id="Issue-2">Issue:</h3><p>You may see an error stating:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock</span><br></pre></td></tr></table></figure><h3 id="Solution-2">Solution:</h3><p>This error indicates that the <code>gitlab-runner</code> user does not have the necessary permissions to access the Docker daemon. You can either add the <code>gitlab-runner</code> user to the Docker group or run <code>gitlab-runner</code> as the root user.</p><p><strong>Option 1: Add <code>gitlab-runner</code> to Docker group</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Create the Docker Group (<span class="keyword">if</span> it doesn<span class="string">&#x27;t already exist):</span></span></span><br><span class="line">sudo groupadd docker</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Add gitlab-runner to the Docker group</span></span></span><br><span class="line">sudo usermod -aG docker gitlab-runner</span><br></pre></td></tr></table></figure><p><strong>Option 2: Run <code>gitlab-runner</code> as root</strong></p><p>Modify the GitLab Runner service file:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/etc/systemd/system/gitlab-runner.service</span></span><br><span class="line"></span><br><span class="line">ExecStart=/usr/bin/gitlab-runner &quot;run&quot; &quot;--working-directory&quot; &quot;/home/gitlab-runner&quot; &quot;--config&quot; &quot;/etc/gitlab-runner/config.toml&quot; &quot;--service&quot; &quot;gitlab-runner&quot; &quot;--user&quot; &quot;root&quot;</span><br></pre></td></tr></table></figure><p>Then, check if the GitLab Runner is running with the correct user:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep gitlab-runner</span><br></pre></td></tr></table></figure><h2 id="3-Dubious-Ownership-in-Repository">3. Dubious Ownership in Repository</h2><h3 id="Issue-3">Issue:</h3><p>Another common error you might face is:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fatal: detected dubious ownership in repository at</span><br></pre></td></tr></table></figure><h3 id="Solution-3">Solution:</h3><p>To resolve this, add the repository to the list of safe directories.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global --add safe.directory &quot;*&quot;</span><br></pre></td></tr></table></figure><h2 id="4-OCI-Runtime-Create-Failed">4. OCI Runtime Create Failed</h2><h3 id="Issue-4">Issue:</h3><p>While starting a container, you might encounter the following error:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OCI runtime create failed: container_linux.go:349: starting container process caused &quot;process_linux.go:319: getting the final child&#x27;s pid from pipe caused &quot;EOF&quot;: unknown</span><br></pre></td></tr></table></figure><h3 id="Solutions">Solutions:</h3><p>This issue can be caused by several factors. Here are three potential solutions:</p><p><strong>Way 1: Increase <code>kernel.pid_max</code></strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sysctl -n kernel.pid_max</span></span><br><span class="line">32768</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sysctl -w kernel.pid_max=100000</span></span><br></pre></td></tr></table></figure><p><strong>Way 2: Increase <code>user.max_user_namespaces</code></strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sysctl -n user.max_user_namespaces</span></span><br><span class="line">0  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">if</span> zero try this</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sysctl -w user.max_user_namespaces=15000</span></span><br></pre></td></tr></table></figure><p><strong>Way 3: Resolve Page Allocation Failure</strong></p><p>Check for page allocation failures:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep -w <span class="string">&#x27;runc:\[1:CHILD\]: page allocation failure&#x27;</span> /var/log/messages | <span class="built_in">tail</span> -n 4</span></span><br><span class="line">Nov 20 16:13:54 ETL010080 kernel: runc:[1:CHILD]: page allocation failure: order:4, mode:0x10c0d0</span><br><span class="line">Nov 20 16:15:46 ETL010080 kernel: runc:[1:CHILD]: page allocation failure: order:4, mode:0x10c0d0</span><br><span class="line">Nov 20 16:16:28 ETL010080 kernel: runc:[1:CHILD]: page allocation failure: order:4, mode:0x10c0d0</span><br><span class="line">Nov 20 16:16:41 ETL010080 kernel: runc:[1:CHILD]: page allocation failure: order:4, mode:0x10c0d0</span><br></pre></td></tr></table></figure><p><strong>Solution 1: Drop Caches</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 3 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure><p><strong>Solution 2: Compact Memory</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/vm/compact_memory</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">or</span></span><br><span class="line">sysctl -w vm.compact_memory=1</span><br></pre></td></tr></table></figure><p>After applying these solutions, remember to restart the GitLab Runner for changes to take effect:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart gitlab-runner</span><br></pre></td></tr></table></figure><h2 id="Conclusion">Conclusion</h2><p>Working with GitLab Runner on CentOS can sometimes present challenges, but with the right approach and solutions, you can overcome these hurdles efficiently. By keeping your tools updated, managing permissions correctly, and tweaking system parameters, you can ensure a smooth CI/CD pipeline. If you encounter any other issues, feel free to explore the GitLab and Docker documentation or reach out to the community for further assistance.</p><p>Happy coding!</p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;Troubleshooting Common Issues with GitLab Runner Shell Executor on CentOS&lt;/h1&gt;
&lt;p&gt;As a senior software engineer, I often encounter various challenges while working with GitLab Runner on CentOS. This blog post aims to address some common issues and provide solutions that can help streamline your CI/CD pipeline. Whether you’re upgrading Git, managing permissions for Docker, or dealing with runtime errors, this guide will offer practical steps to resolve these issues efficiently.&lt;/p&gt;</summary>
    
    
    
    <category term="Infrastructure as Code (IaC)" scheme="https://cloudolife.com/categories/Infrastructure-as-Code-IaC/"/>
    
    <category term="GitLab" scheme="https://cloudolife.com/categories/Infrastructure-as-Code-IaC/GitLab/"/>
    
    <category term="GitLab Runner" scheme="https://cloudolife.com/categories/Infrastructure-as-Code-IaC/GitLab/GitLab-Runner/"/>
    
    
    <category term="GitLab" scheme="https://cloudolife.com/tags/GitLab/"/>
    
    <category term="CI" scheme="https://cloudolife.com/tags/CI/"/>
    
    <category term="CD" scheme="https://cloudolife.com/tags/CD/"/>
    
    <category term="Infrastructure" scheme="https://cloudolife.com/tags/Infrastructure/"/>
    
    <category term="Continuous" scheme="https://cloudolife.com/tags/Continuous/"/>
    
    <category term="Integration" scheme="https://cloudolife.com/tags/Integration/"/>
    
    <category term="(CI)" scheme="https://cloudolife.com/tags/CI/"/>
    
    <category term="Delivery" scheme="https://cloudolife.com/tags/Delivery/"/>
    
    <category term="(CD)" scheme="https://cloudolife.com/tags/CD/"/>
    
    <category term="as" scheme="https://cloudolife.com/tags/as/"/>
    
    <category term="Code" scheme="https://cloudolife.com/tags/Code/"/>
    
    <category term="(IaC)" scheme="https://cloudolife.com/tags/IaC/"/>
    
    <category term="Runner" scheme="https://cloudolife.com/tags/Runner/"/>
    
    <category term="Pipeline" scheme="https://cloudolife.com/tags/Pipeline/"/>
    
    <category term="Trigger" scheme="https://cloudolife.com/tags/Trigger/"/>
    
    <category term="Job" scheme="https://cloudolife.com/tags/Job/"/>
    
  </entry>
  
</feed>
